{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-06-05T19:20:03.053733Z","iopub.execute_input":"2022-06-05T19:20:03.054293Z","iopub.status.idle":"2022-06-05T19:20:03.115518Z","shell.execute_reply.started":"2022-06-05T19:20:03.054183Z","shell.execute_reply":"2022-06-05T19:20:03.114701Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/beerdata/df_stratified_sample.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"df_stratified_s = pd.read_csv(\"../input/beerdata/df_stratified_sample.csv\")\ndf_stratified_s","metadata":{"execution":{"iopub.status.busy":"2022-06-05T19:20:07.409477Z","iopub.execute_input":"2022-06-05T19:20:07.409811Z","iopub.status.idle":"2022-06-05T19:20:07.625600Z","shell.execute_reply.started":"2022-06-05T19:20:07.409783Z","shell.execute_reply":"2022-06-05T19:20:07.624871Z"},"trusted":true},"execution_count":2,"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"       beer_id                               beer_name  brewery_id state_beer  \\\n0         1237                      Pyramid Hefeweizen       403.0         WA   \n1        24436                        Helio Hefeweizen      7122.0         MT   \n2         4011                                  Weizen       452.0         NC   \n3         2249                              Hefeweizen        68.0         MD   \n4         4071                               Snoweizen      1528.0         CA   \n...        ...                                     ...         ...        ...   \n39995   140014                    Hipster Brunch Stout     22564.0         MI   \n39996    54320                       Steam Fired Stout     21554.0         OR   \n39997     1879                Samuel Adams Cream Stout        35.0         MA   \n39998   101578                          Coffee Abraxas     25888.0         MO   \n39999   131782  Vanilla Rye Bourbon County Brand Stout      1146.0         IL   \n\n      country_beer              style availability   abv  \\\n0               US  German Hefeweizen   Year round   5.2   \n1               US  German Hefeweizen   Year round   6.0   \n2               US  German Hefeweizen   Year round   4.9   \n3               US  German Hefeweizen   Year round   4.7   \n4               US  German Hefeweizen   Year round   5.1   \n...            ...                ...          ...   ...   \n39995           US              Stout         Fall  11.0   \n39996           US              Stout   Year round   7.6   \n39997           US              Stout   Year round   4.9   \n39998           US              Stout     Rotating  10.0   \n39999           US              Stout     Rotating  13.6   \n\n                             brewery_name           city  \\\n0                 Pyramid Breweries, Inc.        Seattle   \n1                          Red Lodge Ales      Red Lodge   \n2      Weeping Radish Bavarian Restaurant         Manteo   \n3                      Flying Dog Brewery      Frederick   \n4                Snowshoe Brewing Company         Arnold   \n...                                   ...            ...   \n39995                       Odd Side Ales    Grand Haven   \n39996            Fire Mountain Brew House        Carlton   \n39997  Boston Beer Company (Samuel Adams)  Jamaica Plain   \n39998              Perennial Artisan Ales    Saint Louis   \n39999               Goose Island Beer Co.        Chicago   \n\n                                  types  look  smell  taste  feel  overall  \\\n0                               Brewery  3.25   3.00   3.00  3.00     3.00   \n1      Brewery, Bar, Eatery, Beer-to-go  3.75   3.75   3.75  3.75     3.75   \n2                           Bar, Eatery  3.50   3.00   4.00  3.50     4.00   \n3      Brewery, Bar, Eatery, Beer-to-go  3.50   3.50   3.00  3.50     4.00   \n4                  Brewery, Bar, Eatery  2.50   4.00   3.00  2.50     3.00   \n...                                 ...   ...    ...    ...   ...      ...   \n39995  Brewery, Bar, Eatery, Beer-to-go  4.50   4.50   4.25  4.00     4.25   \n39996               Brewery, Beer-to-go  4.00   4.00   4.00  4.00     4.00   \n39997               Brewery, Beer-to-go  4.00   4.00   4.00  4.00     4.00   \n39998  Brewery, Bar, Eatery, Beer-to-go  4.75   4.50   4.50  4.25     4.50   \n39999          Brewery, Bar, Beer-to-go  4.50   4.75   4.50  4.50     4.75   \n\n       score  \n0       3.02  \n1       3.75  \n2       3.68  \n3       3.40  \n4       3.16  \n...      ...  \n39995   4.30  \n39996   4.00  \n39997   4.00  \n39998   4.49  \n39999   4.61  \n\n[40000 rows x 17 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>beer_id</th>\n      <th>beer_name</th>\n      <th>brewery_id</th>\n      <th>state_beer</th>\n      <th>country_beer</th>\n      <th>style</th>\n      <th>availability</th>\n      <th>abv</th>\n      <th>brewery_name</th>\n      <th>city</th>\n      <th>types</th>\n      <th>look</th>\n      <th>smell</th>\n      <th>taste</th>\n      <th>feel</th>\n      <th>overall</th>\n      <th>score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1237</td>\n      <td>Pyramid Hefeweizen</td>\n      <td>403.0</td>\n      <td>WA</td>\n      <td>US</td>\n      <td>German Hefeweizen</td>\n      <td>Year round</td>\n      <td>5.2</td>\n      <td>Pyramid Breweries, Inc.</td>\n      <td>Seattle</td>\n      <td>Brewery</td>\n      <td>3.25</td>\n      <td>3.00</td>\n      <td>3.00</td>\n      <td>3.00</td>\n      <td>3.00</td>\n      <td>3.02</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>24436</td>\n      <td>Helio Hefeweizen</td>\n      <td>7122.0</td>\n      <td>MT</td>\n      <td>US</td>\n      <td>German Hefeweizen</td>\n      <td>Year round</td>\n      <td>6.0</td>\n      <td>Red Lodge Ales</td>\n      <td>Red Lodge</td>\n      <td>Brewery, Bar, Eatery, Beer-to-go</td>\n      <td>3.75</td>\n      <td>3.75</td>\n      <td>3.75</td>\n      <td>3.75</td>\n      <td>3.75</td>\n      <td>3.75</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>4011</td>\n      <td>Weizen</td>\n      <td>452.0</td>\n      <td>NC</td>\n      <td>US</td>\n      <td>German Hefeweizen</td>\n      <td>Year round</td>\n      <td>4.9</td>\n      <td>Weeping Radish Bavarian Restaurant</td>\n      <td>Manteo</td>\n      <td>Bar, Eatery</td>\n      <td>3.50</td>\n      <td>3.00</td>\n      <td>4.00</td>\n      <td>3.50</td>\n      <td>4.00</td>\n      <td>3.68</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2249</td>\n      <td>Hefeweizen</td>\n      <td>68.0</td>\n      <td>MD</td>\n      <td>US</td>\n      <td>German Hefeweizen</td>\n      <td>Year round</td>\n      <td>4.7</td>\n      <td>Flying Dog Brewery</td>\n      <td>Frederick</td>\n      <td>Brewery, Bar, Eatery, Beer-to-go</td>\n      <td>3.50</td>\n      <td>3.50</td>\n      <td>3.00</td>\n      <td>3.50</td>\n      <td>4.00</td>\n      <td>3.40</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4071</td>\n      <td>Snoweizen</td>\n      <td>1528.0</td>\n      <td>CA</td>\n      <td>US</td>\n      <td>German Hefeweizen</td>\n      <td>Year round</td>\n      <td>5.1</td>\n      <td>Snowshoe Brewing Company</td>\n      <td>Arnold</td>\n      <td>Brewery, Bar, Eatery</td>\n      <td>2.50</td>\n      <td>4.00</td>\n      <td>3.00</td>\n      <td>2.50</td>\n      <td>3.00</td>\n      <td>3.16</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>39995</th>\n      <td>140014</td>\n      <td>Hipster Brunch Stout</td>\n      <td>22564.0</td>\n      <td>MI</td>\n      <td>US</td>\n      <td>Stout</td>\n      <td>Fall</td>\n      <td>11.0</td>\n      <td>Odd Side Ales</td>\n      <td>Grand Haven</td>\n      <td>Brewery, Bar, Eatery, Beer-to-go</td>\n      <td>4.50</td>\n      <td>4.50</td>\n      <td>4.25</td>\n      <td>4.00</td>\n      <td>4.25</td>\n      <td>4.30</td>\n    </tr>\n    <tr>\n      <th>39996</th>\n      <td>54320</td>\n      <td>Steam Fired Stout</td>\n      <td>21554.0</td>\n      <td>OR</td>\n      <td>US</td>\n      <td>Stout</td>\n      <td>Year round</td>\n      <td>7.6</td>\n      <td>Fire Mountain Brew House</td>\n      <td>Carlton</td>\n      <td>Brewery, Beer-to-go</td>\n      <td>4.00</td>\n      <td>4.00</td>\n      <td>4.00</td>\n      <td>4.00</td>\n      <td>4.00</td>\n      <td>4.00</td>\n    </tr>\n    <tr>\n      <th>39997</th>\n      <td>1879</td>\n      <td>Samuel Adams Cream Stout</td>\n      <td>35.0</td>\n      <td>MA</td>\n      <td>US</td>\n      <td>Stout</td>\n      <td>Year round</td>\n      <td>4.9</td>\n      <td>Boston Beer Company (Samuel Adams)</td>\n      <td>Jamaica Plain</td>\n      <td>Brewery, Beer-to-go</td>\n      <td>4.00</td>\n      <td>4.00</td>\n      <td>4.00</td>\n      <td>4.00</td>\n      <td>4.00</td>\n      <td>4.00</td>\n    </tr>\n    <tr>\n      <th>39998</th>\n      <td>101578</td>\n      <td>Coffee Abraxas</td>\n      <td>25888.0</td>\n      <td>MO</td>\n      <td>US</td>\n      <td>Stout</td>\n      <td>Rotating</td>\n      <td>10.0</td>\n      <td>Perennial Artisan Ales</td>\n      <td>Saint Louis</td>\n      <td>Brewery, Bar, Eatery, Beer-to-go</td>\n      <td>4.75</td>\n      <td>4.50</td>\n      <td>4.50</td>\n      <td>4.25</td>\n      <td>4.50</td>\n      <td>4.49</td>\n    </tr>\n    <tr>\n      <th>39999</th>\n      <td>131782</td>\n      <td>Vanilla Rye Bourbon County Brand Stout</td>\n      <td>1146.0</td>\n      <td>IL</td>\n      <td>US</td>\n      <td>Stout</td>\n      <td>Rotating</td>\n      <td>13.6</td>\n      <td>Goose Island Beer Co.</td>\n      <td>Chicago</td>\n      <td>Brewery, Bar, Beer-to-go</td>\n      <td>4.50</td>\n      <td>4.75</td>\n      <td>4.50</td>\n      <td>4.50</td>\n      <td>4.75</td>\n      <td>4.61</td>\n    </tr>\n  </tbody>\n</table>\n<p>40000 rows × 17 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"#Encode string values\nfrom sklearn.preprocessing import LabelEncoder\nle = LabelEncoder()\nencoded_df_sample = df_stratified_s.copy()\nencoded_df_sample[\"state_beer\"] = le.fit_transform(encoded_df_sample[\"state_beer\"])\nencoded_df_sample[\"availability\"] = le.fit_transform(encoded_df_sample[\"availability\"])\nencoded_df_sample[\"types\"] = le.fit_transform(encoded_df_sample[\"types\"])\nencoded_df_sample[\"style\"] = le.fit_transform(encoded_df_sample[\"style\"])\nencoded_df_sample = encoded_df_sample.drop(['beer_name', 'country_beer','brewery_name','city','brewery_id','beer_id','smell','look','feel','score','overall'], axis=1)\nencoded_df_sample","metadata":{"execution":{"iopub.status.busy":"2022-06-05T19:20:12.049263Z","iopub.execute_input":"2022-06-05T19:20:12.049612Z","iopub.status.idle":"2022-06-05T19:20:12.537496Z","shell.execute_reply.started":"2022-06-05T19:20:12.049581Z","shell.execute_reply":"2022-06-05T19:20:12.536725Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"       state_beer  style  availability   abv  types  taste\n0              47     18             6   5.2      1   3.00\n1              26     18             6   6.0      5   3.75\n2              27     18             6   4.9      0   4.00\n3              20     18             6   4.7      5   3.00\n4               4     18             6   5.1      4   3.00\n...           ...    ...           ...   ...    ...    ...\n39995          22     36             0  11.0      5   4.25\n39996          37     36             6   7.6     10   4.00\n39997          19     36             6   4.9     10   4.00\n39998          24     36             2  10.0      5   4.50\n39999          14     36             2  13.6      3   4.50\n\n[40000 rows x 6 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>state_beer</th>\n      <th>style</th>\n      <th>availability</th>\n      <th>abv</th>\n      <th>types</th>\n      <th>taste</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>47</td>\n      <td>18</td>\n      <td>6</td>\n      <td>5.2</td>\n      <td>1</td>\n      <td>3.00</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>26</td>\n      <td>18</td>\n      <td>6</td>\n      <td>6.0</td>\n      <td>5</td>\n      <td>3.75</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>27</td>\n      <td>18</td>\n      <td>6</td>\n      <td>4.9</td>\n      <td>0</td>\n      <td>4.00</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>20</td>\n      <td>18</td>\n      <td>6</td>\n      <td>4.7</td>\n      <td>5</td>\n      <td>3.00</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>18</td>\n      <td>6</td>\n      <td>5.1</td>\n      <td>4</td>\n      <td>3.00</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>39995</th>\n      <td>22</td>\n      <td>36</td>\n      <td>0</td>\n      <td>11.0</td>\n      <td>5</td>\n      <td>4.25</td>\n    </tr>\n    <tr>\n      <th>39996</th>\n      <td>37</td>\n      <td>36</td>\n      <td>6</td>\n      <td>7.6</td>\n      <td>10</td>\n      <td>4.00</td>\n    </tr>\n    <tr>\n      <th>39997</th>\n      <td>19</td>\n      <td>36</td>\n      <td>6</td>\n      <td>4.9</td>\n      <td>10</td>\n      <td>4.00</td>\n    </tr>\n    <tr>\n      <th>39998</th>\n      <td>24</td>\n      <td>36</td>\n      <td>2</td>\n      <td>10.0</td>\n      <td>5</td>\n      <td>4.50</td>\n    </tr>\n    <tr>\n      <th>39999</th>\n      <td>14</td>\n      <td>36</td>\n      <td>2</td>\n      <td>13.6</td>\n      <td>3</td>\n      <td>4.50</td>\n    </tr>\n  </tbody>\n</table>\n<p>40000 rows × 6 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# import dependences\nimport numpy as np\nimport optuna\nimport sklearn.datasets\nimport sklearn.metrics\nfrom sklearn.model_selection import train_test_split\nimport xgboost as xgb","metadata":{"execution":{"iopub.status.busy":"2022-06-05T19:20:16.448287Z","iopub.execute_input":"2022-06-05T19:20:16.448625Z","iopub.status.idle":"2022-06-05T19:20:17.326173Z","shell.execute_reply.started":"2022-06-05T19:20:16.448597Z","shell.execute_reply":"2022-06-05T19:20:17.325357Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"#Data and target \ny = encoded_df_sample['style'].values\nX = encoded_df_sample.copy().drop(columns =['style'])","metadata":{"execution":{"iopub.status.busy":"2022-06-05T19:20:21.763652Z","iopub.execute_input":"2022-06-05T19:20:21.764201Z","iopub.status.idle":"2022-06-05T19:20:21.773058Z","shell.execute_reply.started":"2022-06-05T19:20:21.764164Z","shell.execute_reply":"2022-06-05T19:20:21.772297Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"#Scale the input data\nfrom sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\nX_scaled = scaler.fit_transform(X)","metadata":{"execution":{"iopub.status.busy":"2022-06-05T19:20:25.704713Z","iopub.execute_input":"2022-06-05T19:20:25.705577Z","iopub.status.idle":"2022-06-05T19:20:25.718382Z","shell.execute_reply.started":"2022-06-05T19:20:25.705542Z","shell.execute_reply":"2022-06-05T19:20:25.717489Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"import optuna\nimport sklearn.datasets\nimport sklearn.metrics\nfrom sklearn.model_selection import train_test_split\nimport xgboost as xgb","metadata":{"execution":{"iopub.status.busy":"2022-06-05T19:20:27.815711Z","iopub.execute_input":"2022-06-05T19:20:27.816062Z","iopub.status.idle":"2022-06-05T19:20:27.820360Z","shell.execute_reply.started":"2022-06-05T19:20:27.816033Z","shell.execute_reply":"2022-06-05T19:20:27.819528Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# hyperparameter tuning using optuna\n# reference: https://www.kaggle.com/code/hamzaghanmi/xgboost-catboost-using-optuna/notebook?scriptVersionId=94510532\ndef objective(trial,data=X_scaled,target=y):\n    \n    train_x, test_x, train_y, test_y = train_test_split(data, target, test_size=0.33,random_state=1)\n    \n    param = {\n        'tree_method':'gpu_hist', \n        'lambda': trial.suggest_loguniform('lambda', 1e-3, 10.0),\n        'alpha': trial.suggest_loguniform('alpha', 1e-3, 10.0),\n        'colsample_bytree': trial.suggest_categorical('colsample_bytree', [0.3,0.4,0.5,0.6,0.7,0.8,0.9, 1.0]),\n        'subsample': trial.suggest_categorical('subsample', [0.4,0.5,0.6,0.7,0.8,1.0]),\n        'learning_rate': trial.suggest_categorical('learning_rate', [0.008,0.01,0.012,0.014,0.016,0.018, 0.02]),\n        'n_estimators': 200,\n        'max_depth': trial.suggest_categorical('max_depth', [5,7,9,11,13,15,17]),\n        'random_state': trial.suggest_categorical('random_state', [2020]),\n        'min_child_weight': trial.suggest_int('min_child_weight', 1, 300),\n    }\n    model = xgb.XGBClassifier(**param)  \n    \n    model.fit(train_x,train_y,eval_set=[(test_x,test_y)],early_stopping_rounds=100,verbose=False)\n    \n    preds = model.predict(test_x)\n    \n    accuracy = sklearn.metrics.accuracy_score(test_y, preds)\n    \n    return accuracy","metadata":{"execution":{"iopub.status.busy":"2022-06-05T13:58:49.654606Z","iopub.execute_input":"2022-06-05T13:58:49.655337Z","iopub.status.idle":"2022-06-05T13:58:49.666538Z","shell.execute_reply.started":"2022-06-05T13:58:49.655303Z","shell.execute_reply":"2022-06-05T13:58:49.665769Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# run the study\nstudy = optuna.create_study(direction='maximize')\nstudy.optimize(objective, n_trials=50)\nprint('Number of finished trials:', len(study.trials))\nprint('Best trial:', study.best_trial.params)","metadata":{"execution":{"iopub.status.busy":"2022-06-05T13:58:49.667808Z","iopub.execute_input":"2022-06-05T13:58:49.668201Z","iopub.status.idle":"2022-06-05T14:15:18.276008Z","shell.execute_reply.started":"2022-06-05T13:58:49.668138Z","shell.execute_reply":"2022-06-05T14:15:18.274708Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stderr","text":"\u001b[32m[I 2022-06-05 13:58:49,673]\u001b[0m A new study created in memory with name: no-name-25e955e1-5c52-47c7-9221-8db725f5de7f\u001b[0m\n/opt/conda/lib/python3.7/site-packages/xgboost/sklearn.py:797: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n  UserWarning,\n\u001b[32m[I 2022-06-05 13:59:07,478]\u001b[0m Trial 0 finished with value: 0.14068181818181819 and parameters: {'lambda': 1.2212397088555664, 'alpha': 0.327260173408721, 'colsample_bytree': 0.8, 'subsample': 0.8, 'learning_rate': 0.01, 'max_depth': 17, 'random_state': 2020, 'min_child_weight': 177}. Best is trial 0 with value: 0.14068181818181819.\u001b[0m\n/opt/conda/lib/python3.7/site-packages/xgboost/sklearn.py:797: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n  UserWarning,\n\u001b[32m[I 2022-06-05 13:59:12,053]\u001b[0m Trial 1 finished with value: 0.15795454545454546 and parameters: {'lambda': 0.003549429352118488, 'alpha': 3.087064616868977, 'colsample_bytree': 0.3, 'subsample': 0.7, 'learning_rate': 0.012, 'max_depth': 5, 'random_state': 2020, 'min_child_weight': 132}. Best is trial 1 with value: 0.15795454545454546.\u001b[0m\n/opt/conda/lib/python3.7/site-packages/xgboost/sklearn.py:797: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n  UserWarning,\n\u001b[32m[I 2022-06-05 13:59:21,360]\u001b[0m Trial 2 finished with value: 0.2521969696969697 and parameters: {'lambda': 0.19942627190565007, 'alpha': 1.289422940942519, 'colsample_bytree': 0.9, 'subsample': 0.7, 'learning_rate': 0.02, 'max_depth': 13, 'random_state': 2020, 'min_child_weight': 81}. Best is trial 2 with value: 0.2521969696969697.\u001b[0m\n/opt/conda/lib/python3.7/site-packages/xgboost/sklearn.py:797: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n  UserWarning,\n\u001b[32m[I 2022-06-05 13:59:29,824]\u001b[0m Trial 3 finished with value: 0.23553030303030303 and parameters: {'lambda': 0.010106954795198814, 'alpha': 0.17633316202178645, 'colsample_bytree': 0.4, 'subsample': 0.7, 'learning_rate': 0.008, 'max_depth': 9, 'random_state': 2020, 'min_child_weight': 57}. Best is trial 2 with value: 0.2521969696969697.\u001b[0m\n/opt/conda/lib/python3.7/site-packages/xgboost/sklearn.py:797: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n  UserWarning,\n\u001b[32m[I 2022-06-05 13:59:33,673]\u001b[0m Trial 4 finished with value: 0.09075757575757576 and parameters: {'lambda': 1.012867927513324, 'alpha': 0.16311295623915176, 'colsample_bytree': 0.7, 'subsample': 0.5, 'learning_rate': 0.016, 'max_depth': 5, 'random_state': 2020, 'min_child_weight': 228}. Best is trial 2 with value: 0.2521969696969697.\u001b[0m\n/opt/conda/lib/python3.7/site-packages/xgboost/sklearn.py:797: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n  UserWarning,\n\u001b[32m[I 2022-06-05 13:59:39,172]\u001b[0m Trial 5 finished with value: 0.1784090909090909 and parameters: {'lambda': 0.15810508045530905, 'alpha': 0.022987053936107286, 'colsample_bytree': 0.4, 'subsample': 0.4, 'learning_rate': 0.01, 'max_depth': 9, 'random_state': 2020, 'min_child_weight': 79}. Best is trial 2 with value: 0.2521969696969697.\u001b[0m\n/opt/conda/lib/python3.7/site-packages/xgboost/sklearn.py:797: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n  UserWarning,\n\u001b[32m[I 2022-06-05 13:59:43,551]\u001b[0m Trial 6 finished with value: 0.11916666666666667 and parameters: {'lambda': 0.06296764415490054, 'alpha': 0.031526225762042635, 'colsample_bytree': 0.5, 'subsample': 0.7, 'learning_rate': 0.01, 'max_depth': 7, 'random_state': 2020, 'min_child_weight': 209}. Best is trial 2 with value: 0.2521969696969697.\u001b[0m\n/opt/conda/lib/python3.7/site-packages/xgboost/sklearn.py:797: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n  UserWarning,\n\u001b[32m[I 2022-06-05 13:59:50,522]\u001b[0m Trial 7 finished with value: 0.20666666666666667 and parameters: {'lambda': 0.08888178685630868, 'alpha': 0.48215973034544557, 'colsample_bytree': 0.7, 'subsample': 0.7, 'learning_rate': 0.016, 'max_depth': 11, 'random_state': 2020, 'min_child_weight': 101}. Best is trial 2 with value: 0.2521969696969697.\u001b[0m\n/opt/conda/lib/python3.7/site-packages/xgboost/sklearn.py:797: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n  UserWarning,\n\u001b[32m[I 2022-06-05 13:59:57,768]\u001b[0m Trial 8 finished with value: 0.06477272727272727 and parameters: {'lambda': 0.0021557370562391054, 'alpha': 8.611480084904086, 'colsample_bytree': 0.8, 'subsample': 0.5, 'learning_rate': 0.014, 'max_depth': 15, 'random_state': 2020, 'min_child_weight': 271}. Best is trial 2 with value: 0.2521969696969697.\u001b[0m\n/opt/conda/lib/python3.7/site-packages/xgboost/sklearn.py:797: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n  UserWarning,\n\u001b[32m[I 2022-06-05 14:00:05,073]\u001b[0m Trial 9 finished with value: 0.22984848484848486 and parameters: {'lambda': 4.050985715035236, 'alpha': 0.6966676134241258, 'colsample_bytree': 0.5, 'subsample': 0.7, 'learning_rate': 0.014, 'max_depth': 11, 'random_state': 2020, 'min_child_weight': 74}. Best is trial 2 with value: 0.2521969696969697.\u001b[0m\n/opt/conda/lib/python3.7/site-packages/xgboost/sklearn.py:797: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n  UserWarning,\n\u001b[32m[I 2022-06-05 14:00:57,296]\u001b[0m Trial 10 finished with value: 0.546969696969697 and parameters: {'lambda': 0.023212806094648084, 'alpha': 0.0036740159021353834, 'colsample_bytree': 0.9, 'subsample': 0.6, 'learning_rate': 0.02, 'max_depth': 13, 'random_state': 2020, 'min_child_weight': 4}. Best is trial 10 with value: 0.546969696969697.\u001b[0m\n/opt/conda/lib/python3.7/site-packages/xgboost/sklearn.py:797: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n  UserWarning,\n\u001b[32m[I 2022-06-05 14:01:50,109]\u001b[0m Trial 11 finished with value: 0.5475757575757576 and parameters: {'lambda': 0.021107984717000323, 'alpha': 0.0013409243154017625, 'colsample_bytree': 0.9, 'subsample': 0.6, 'learning_rate': 0.02, 'max_depth': 13, 'random_state': 2020, 'min_child_weight': 4}. Best is trial 11 with value: 0.5475757575757576.\u001b[0m\n/opt/conda/lib/python3.7/site-packages/xgboost/sklearn.py:797: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n  UserWarning,\n\u001b[32m[I 2022-06-05 14:02:04,194]\u001b[0m Trial 12 finished with value: 0.3468181818181818 and parameters: {'lambda': 0.016562002692863106, 'alpha': 0.0010739209612255238, 'colsample_bytree': 0.9, 'subsample': 0.6, 'learning_rate': 0.02, 'max_depth': 13, 'random_state': 2020, 'min_child_weight': 31}. Best is trial 11 with value: 0.5475757575757576.\u001b[0m\n/opt/conda/lib/python3.7/site-packages/xgboost/sklearn.py:797: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n  UserWarning,\n\u001b[32m[I 2022-06-05 14:03:45,841]\u001b[0m Trial 13 finished with value: 0.6291666666666667 and parameters: {'lambda': 0.02128232993738036, 'alpha': 0.0010978213771125056, 'colsample_bytree': 0.9, 'subsample': 0.6, 'learning_rate': 0.018, 'max_depth': 13, 'random_state': 2020, 'min_child_weight': 1}. Best is trial 13 with value: 0.6291666666666667.\u001b[0m\n/opt/conda/lib/python3.7/site-packages/xgboost/sklearn.py:797: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n  UserWarning,\n\u001b[32m[I 2022-06-05 14:04:44,321]\u001b[0m Trial 14 finished with value: 0.5417424242424242 and parameters: {'lambda': 0.0010723856303012822, 'alpha': 0.0011326731451181374, 'colsample_bytree': 0.6, 'subsample': 0.6, 'learning_rate': 0.018, 'max_depth': 13, 'random_state': 2020, 'min_child_weight': 3}. Best is trial 13 with value: 0.6291666666666667.\u001b[0m\n/opt/conda/lib/python3.7/site-packages/xgboost/sklearn.py:797: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n  UserWarning,\n\u001b[32m[I 2022-06-05 14:04:52,587]\u001b[0m Trial 15 finished with value: 0.2362121212121212 and parameters: {'lambda': 0.008906347786725879, 'alpha': 0.0072221186044505595, 'colsample_bytree': 1.0, 'subsample': 1.0, 'learning_rate': 0.018, 'max_depth': 13, 'random_state': 2020, 'min_child_weight': 128}. Best is trial 13 with value: 0.6291666666666667.\u001b[0m\n/opt/conda/lib/python3.7/site-packages/xgboost/sklearn.py:797: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n  UserWarning,\n\u001b[32m[I 2022-06-05 14:05:03,890]\u001b[0m Trial 16 finished with value: 0.3162121212121212 and parameters: {'lambda': 0.059307902896237344, 'alpha': 0.0037969655081485252, 'colsample_bytree': 0.9, 'subsample': 0.6, 'learning_rate': 0.018, 'max_depth': 7, 'random_state': 2020, 'min_child_weight': 38}. Best is trial 13 with value: 0.6291666666666667.\u001b[0m\n/opt/conda/lib/python3.7/site-packages/xgboost/sklearn.py:797: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n  UserWarning,\n\u001b[32m[I 2022-06-05 14:05:20,100]\u001b[0m Trial 17 finished with value: 0.2959090909090909 and parameters: {'lambda': 0.3395234834553104, 'alpha': 0.03341846648876918, 'colsample_bytree': 0.9, 'subsample': 0.6, 'learning_rate': 0.008, 'max_depth': 15, 'random_state': 2020, 'min_child_weight': 32}. Best is trial 13 with value: 0.6291666666666667.\u001b[0m\n/opt/conda/lib/python3.7/site-packages/xgboost/sklearn.py:797: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n  UserWarning,\n\u001b[32m[I 2022-06-05 14:05:36,067]\u001b[0m Trial 18 finished with value: 0.18606060606060607 and parameters: {'lambda': 0.032740713072601936, 'alpha': 0.010020457520910783, 'colsample_bytree': 1.0, 'subsample': 1.0, 'learning_rate': 0.012, 'max_depth': 17, 'random_state': 2020, 'min_child_weight': 160}. Best is trial 13 with value: 0.6291666666666667.\u001b[0m\n/opt/conda/lib/python3.7/site-packages/xgboost/sklearn.py:797: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n  UserWarning,\n\u001b[32m[I 2022-06-05 14:05:41,277]\u001b[0m Trial 19 finished with value: 0.10833333333333334 and parameters: {'lambda': 0.005265227352150049, 'alpha': 0.0023649814771481504, 'colsample_bytree': 0.6, 'subsample': 0.8, 'learning_rate': 0.018, 'max_depth': 13, 'random_state': 2020, 'min_child_weight': 273}. Best is trial 13 with value: 0.6291666666666667.\u001b[0m\n/opt/conda/lib/python3.7/site-packages/xgboost/sklearn.py:797: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n  UserWarning,\n\u001b[32m[I 2022-06-05 14:05:58,619]\u001b[0m Trial 20 finished with value: 0.3275757575757576 and parameters: {'lambda': 0.03043323619489913, 'alpha': 0.06457687390870437, 'colsample_bytree': 0.3, 'subsample': 0.4, 'learning_rate': 0.02, 'max_depth': 13, 'random_state': 2020, 'min_child_weight': 1}. Best is trial 13 with value: 0.6291666666666667.\u001b[0m\n/opt/conda/lib/python3.7/site-packages/xgboost/sklearn.py:797: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n  UserWarning,\n\u001b[32m[I 2022-06-05 14:06:45,029]\u001b[0m Trial 21 finished with value: 0.5281818181818182 and parameters: {'lambda': 0.020297448326563623, 'alpha': 0.0026025387487859887, 'colsample_bytree': 0.9, 'subsample': 0.6, 'learning_rate': 0.02, 'max_depth': 13, 'random_state': 2020, 'min_child_weight': 5}. Best is trial 13 with value: 0.6291666666666667.\u001b[0m\n/opt/conda/lib/python3.7/site-packages/xgboost/sklearn.py:797: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n  UserWarning,\n\u001b[32m[I 2022-06-05 14:06:56,913]\u001b[0m Trial 22 finished with value: 0.31696969696969696 and parameters: {'lambda': 0.00903707997043728, 'alpha': 0.007001319905356979, 'colsample_bytree': 0.9, 'subsample': 0.6, 'learning_rate': 0.02, 'max_depth': 13, 'random_state': 2020, 'min_child_weight': 40}. Best is trial 13 with value: 0.6291666666666667.\u001b[0m\n/opt/conda/lib/python3.7/site-packages/xgboost/sklearn.py:797: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n  UserWarning,\n\u001b[32m[I 2022-06-05 14:07:15,836]\u001b[0m Trial 23 finished with value: 0.39704545454545453 and parameters: {'lambda': 0.03693565806518058, 'alpha': 0.0022360690660492622, 'colsample_bytree': 0.9, 'subsample': 0.6, 'learning_rate': 0.02, 'max_depth': 13, 'random_state': 2020, 'min_child_weight': 19}. Best is trial 13 with value: 0.6291666666666667.\u001b[0m\n/opt/conda/lib/python3.7/site-packages/xgboost/sklearn.py:797: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n  UserWarning,\n\u001b[32m[I 2022-06-05 14:07:25,849]\u001b[0m Trial 24 finished with value: 0.28204545454545454 and parameters: {'lambda': 0.015773663152099673, 'alpha': 0.0010043412271551653, 'colsample_bytree': 0.9, 'subsample': 0.6, 'learning_rate': 0.02, 'max_depth': 13, 'random_state': 2020, 'min_child_weight': 54}. Best is trial 13 with value: 0.6291666666666667.\u001b[0m\n/opt/conda/lib/python3.7/site-packages/xgboost/sklearn.py:797: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n  UserWarning,\n\u001b[32m[I 2022-06-05 14:07:33,251]\u001b[0m Trial 25 finished with value: 0.2103030303030303 and parameters: {'lambda': 0.00431932988566919, 'alpha': 0.00982751801774967, 'colsample_bytree': 0.9, 'subsample': 0.6, 'learning_rate': 0.018, 'max_depth': 13, 'random_state': 2020, 'min_child_weight': 101}. Best is trial 13 with value: 0.6291666666666667.\u001b[0m\n/opt/conda/lib/python3.7/site-packages/xgboost/sklearn.py:797: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n  UserWarning,\n\u001b[32m[I 2022-06-05 14:07:41,962]\u001b[0m Trial 26 finished with value: 0.26386363636363636 and parameters: {'lambda': 0.3908232393165017, 'alpha': 0.004342670891525149, 'colsample_bytree': 0.9, 'subsample': 0.6, 'learning_rate': 0.02, 'max_depth': 5, 'random_state': 2020, 'min_child_weight': 61}. Best is trial 13 with value: 0.6291666666666667.\u001b[0m\n/opt/conda/lib/python3.7/site-packages/xgboost/sklearn.py:797: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n  UserWarning,\n\u001b[32m[I 2022-06-05 14:08:08,777]\u001b[0m Trial 27 finished with value: 0.37454545454545457 and parameters: {'lambda': 0.0016223072844789342, 'alpha': 0.017677924596838018, 'colsample_bytree': 0.9, 'subsample': 0.6, 'learning_rate': 0.014, 'max_depth': 17, 'random_state': 2020, 'min_child_weight': 20}. Best is trial 13 with value: 0.6291666666666667.\u001b[0m\n/opt/conda/lib/python3.7/site-packages/xgboost/sklearn.py:797: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n  UserWarning,\n\u001b[32m[I 2022-06-05 14:08:14,442]\u001b[0m Trial 28 finished with value: 0.11492424242424243 and parameters: {'lambda': 0.11944278396777983, 'alpha': 0.001683058096130708, 'colsample_bytree': 0.8, 'subsample': 0.4, 'learning_rate': 0.008, 'max_depth': 11, 'random_state': 2020, 'min_child_weight': 117}. Best is trial 13 with value: 0.6291666666666667.\u001b[0m\n/opt/conda/lib/python3.7/site-packages/xgboost/sklearn.py:797: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n  UserWarning,\n\u001b[32m[I 2022-06-05 14:08:18,176]\u001b[0m Trial 29 finished with value: 0.09295454545454546 and parameters: {'lambda': 0.049045751519441835, 'alpha': 0.004793157416138315, 'colsample_bytree': 0.3, 'subsample': 0.8, 'learning_rate': 0.012, 'max_depth': 9, 'random_state': 2020, 'min_child_weight': 299}. Best is trial 13 with value: 0.6291666666666667.\u001b[0m\n/opt/conda/lib/python3.7/site-packages/xgboost/sklearn.py:797: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n  UserWarning,\n\u001b[32m[I 2022-06-05 14:08:25,451]\u001b[0m Trial 30 finished with value: 0.10621212121212122 and parameters: {'lambda': 0.01914484809731469, 'alpha': 0.06224845885682631, 'colsample_bytree': 0.6, 'subsample': 0.5, 'learning_rate': 0.016, 'max_depth': 15, 'random_state': 2020, 'min_child_weight': 185}. Best is trial 13 with value: 0.6291666666666667.\u001b[0m\n/opt/conda/lib/python3.7/site-packages/xgboost/sklearn.py:797: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n  UserWarning,\n\u001b[32m[I 2022-06-05 14:09:08,406]\u001b[0m Trial 31 finished with value: 0.5011363636363636 and parameters: {'lambda': 0.0013215793867499526, 'alpha': 0.0011048948033976665, 'colsample_bytree': 0.6, 'subsample': 0.6, 'learning_rate': 0.018, 'max_depth': 13, 'random_state': 2020, 'min_child_weight': 5}. Best is trial 13 with value: 0.6291666666666667.\u001b[0m\n/opt/conda/lib/python3.7/site-packages/xgboost/sklearn.py:797: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n  UserWarning,\n\u001b[32m[I 2022-06-05 14:10:20,360]\u001b[0m Trial 32 finished with value: 0.5720454545454545 and parameters: {'lambda': 0.0022476346331545493, 'alpha': 0.0017308470280384739, 'colsample_bytree': 0.6, 'subsample': 0.6, 'learning_rate': 0.018, 'max_depth': 13, 'random_state': 2020, 'min_child_weight': 2}. Best is trial 13 with value: 0.6291666666666667.\u001b[0m\n/opt/conda/lib/python3.7/site-packages/xgboost/sklearn.py:797: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n  UserWarning,\n\u001b[32m[I 2022-06-05 14:10:35,246]\u001b[0m Trial 33 finished with value: 0.35 and parameters: {'lambda': 0.002577916634812059, 'alpha': 0.0031851919816107146, 'colsample_bytree': 0.6, 'subsample': 0.6, 'learning_rate': 0.018, 'max_depth': 13, 'random_state': 2020, 'min_child_weight': 26}. Best is trial 13 with value: 0.6291666666666667.\u001b[0m\n/opt/conda/lib/python3.7/site-packages/xgboost/sklearn.py:797: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n  UserWarning,\n\u001b[32m[I 2022-06-05 14:10:48,258]\u001b[0m Trial 34 finished with value: 0.32242424242424245 and parameters: {'lambda': 0.006181165538309222, 'alpha': 0.001772074212898187, 'colsample_bytree': 0.4, 'subsample': 1.0, 'learning_rate': 0.018, 'max_depth': 13, 'random_state': 2020, 'min_child_weight': 42}. Best is trial 13 with value: 0.6291666666666667.\u001b[0m\n/opt/conda/lib/python3.7/site-packages/xgboost/sklearn.py:797: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n  UserWarning,\n\u001b[32m[I 2022-06-05 14:10:58,530]\u001b[0m Trial 35 finished with value: 0.2887878787878788 and parameters: {'lambda': 0.002773562619412498, 'alpha': 0.012597768941968986, 'colsample_bytree': 0.7, 'subsample': 0.8, 'learning_rate': 0.02, 'max_depth': 7, 'random_state': 2020, 'min_child_weight': 57}. Best is trial 13 with value: 0.6291666666666667.\u001b[0m\n/opt/conda/lib/python3.7/site-packages/xgboost/sklearn.py:797: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n  UserWarning,\n\u001b[32m[I 2022-06-05 14:11:10,464]\u001b[0m Trial 36 finished with value: 0.34424242424242424 and parameters: {'lambda': 0.011445989802217131, 'alpha': 0.005554519876646662, 'colsample_bytree': 1.0, 'subsample': 0.6, 'learning_rate': 0.012, 'max_depth': 5, 'random_state': 2020, 'min_child_weight': 17}. Best is trial 13 with value: 0.6291666666666667.\u001b[0m\n/opt/conda/lib/python3.7/site-packages/xgboost/sklearn.py:797: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n  UserWarning,\n\u001b[32m[I 2022-06-05 14:11:25,602]\u001b[0m Trial 37 finished with value: 0.18924242424242424 and parameters: {'lambda': 0.19987269621647658, 'alpha': 0.0016719029721498637, 'colsample_bytree': 0.5, 'subsample': 0.6, 'learning_rate': 0.01, 'max_depth': 17, 'random_state': 2020, 'min_child_weight': 96}. Best is trial 13 with value: 0.6291666666666667.\u001b[0m\n/opt/conda/lib/python3.7/site-packages/xgboost/sklearn.py:797: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n  UserWarning,\n\u001b[32m[I 2022-06-05 14:11:32,340]\u001b[0m Trial 38 finished with value: 0.20787878787878789 and parameters: {'lambda': 0.0060582630402136834, 'alpha': 0.00323419831952717, 'colsample_bytree': 0.4, 'subsample': 0.5, 'learning_rate': 0.018, 'max_depth': 9, 'random_state': 2020, 'min_child_weight': 68}. Best is trial 13 with value: 0.6291666666666667.\u001b[0m\n/opt/conda/lib/python3.7/site-packages/xgboost/sklearn.py:797: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n  UserWarning,\n\u001b[32m[I 2022-06-05 14:11:41,488]\u001b[0m Trial 39 finished with value: 0.24856060606060607 and parameters: {'lambda': 0.082254240283562, 'alpha': 0.0017387310877734245, 'colsample_bytree': 0.8, 'subsample': 0.4, 'learning_rate': 0.016, 'max_depth': 13, 'random_state': 2020, 'min_child_weight': 46}. Best is trial 13 with value: 0.6291666666666667.\u001b[0m\n/opt/conda/lib/python3.7/site-packages/xgboost/sklearn.py:797: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n  UserWarning,\n\u001b[32m[I 2022-06-05 14:11:49,299]\u001b[0m Trial 40 finished with value: 0.1878030303030303 and parameters: {'lambda': 0.9409630121747792, 'alpha': 3.616228501410253, 'colsample_bytree': 0.9, 'subsample': 0.6, 'learning_rate': 0.01, 'max_depth': 13, 'random_state': 2020, 'min_child_weight': 86}. Best is trial 13 with value: 0.6291666666666667.\u001b[0m\n/opt/conda/lib/python3.7/site-packages/xgboost/sklearn.py:797: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n  UserWarning,\n\u001b[32m[I 2022-06-05 14:12:47,831]\u001b[0m Trial 41 finished with value: 0.5413636363636364 and parameters: {'lambda': 0.001811969414697297, 'alpha': 0.0010602887519383856, 'colsample_bytree': 0.6, 'subsample': 0.6, 'learning_rate': 0.018, 'max_depth': 13, 'random_state': 2020, 'min_child_weight': 3}. Best is trial 13 with value: 0.6291666666666667.\u001b[0m\n/opt/conda/lib/python3.7/site-packages/xgboost/sklearn.py:797: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n  UserWarning,\n\u001b[32m[I 2022-06-05 14:13:08,598]\u001b[0m Trial 42 finished with value: 0.3993181818181818 and parameters: {'lambda': 0.001157957684050205, 'alpha': 0.0016355109768504423, 'colsample_bytree': 0.6, 'subsample': 0.6, 'learning_rate': 0.018, 'max_depth': 13, 'random_state': 2020, 'min_child_weight': 15}. Best is trial 13 with value: 0.6291666666666667.\u001b[0m\n/opt/conda/lib/python3.7/site-packages/xgboost/sklearn.py:797: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n  UserWarning,\n\u001b[32m[I 2022-06-05 14:13:28,100]\u001b[0m Trial 43 finished with value: 0.3934848484848485 and parameters: {'lambda': 0.003515251585542527, 'alpha': 0.0029299889632939872, 'colsample_bytree': 0.6, 'subsample': 0.6, 'learning_rate': 0.018, 'max_depth': 13, 'random_state': 2020, 'min_child_weight': 16}. Best is trial 13 with value: 0.6291666666666667.\u001b[0m\n/opt/conda/lib/python3.7/site-packages/xgboost/sklearn.py:797: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n  UserWarning,\n\u001b[32m[I 2022-06-05 14:14:29,720]\u001b[0m Trial 44 finished with value: 0.5320454545454546 and parameters: {'lambda': 0.0011014685161094316, 'alpha': 0.2615989414534082, 'colsample_bytree': 0.6, 'subsample': 0.7, 'learning_rate': 0.008, 'max_depth': 11, 'random_state': 2020, 'min_child_weight': 2}. Best is trial 13 with value: 0.6291666666666667.\u001b[0m\n/opt/conda/lib/python3.7/site-packages/xgboost/sklearn.py:797: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n  UserWarning,\n\u001b[32m[I 2022-06-05 14:14:43,063]\u001b[0m Trial 45 finished with value: 0.31431818181818183 and parameters: {'lambda': 0.012468314871667049, 'alpha': 0.0014105409976887312, 'colsample_bytree': 0.7, 'subsample': 0.6, 'learning_rate': 0.014, 'max_depth': 13, 'random_state': 2020, 'min_child_weight': 31}. Best is trial 13 with value: 0.6291666666666667.\u001b[0m\n/opt/conda/lib/python3.7/site-packages/xgboost/sklearn.py:797: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n  UserWarning,\n\u001b[32m[I 2022-06-05 14:14:48,250]\u001b[0m Trial 46 finished with value: 0.15075757575757576 and parameters: {'lambda': 4.131651468806721, 'alpha': 0.0052674537325182675, 'colsample_bytree': 0.5, 'subsample': 1.0, 'learning_rate': 0.018, 'max_depth': 7, 'random_state': 2020, 'min_child_weight': 221}. Best is trial 13 with value: 0.6291666666666667.\u001b[0m\n/opt/conda/lib/python3.7/site-packages/xgboost/sklearn.py:797: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n  UserWarning,\n\u001b[32m[I 2022-06-05 14:14:57,777]\u001b[0m Trial 47 finished with value: 0.2290151515151515 and parameters: {'lambda': 0.003678910948493423, 'alpha': 0.002494556035884295, 'colsample_bytree': 0.3, 'subsample': 0.6, 'learning_rate': 0.02, 'max_depth': 15, 'random_state': 2020, 'min_child_weight': 45}. Best is trial 13 with value: 0.6291666666666667.\u001b[0m\n/opt/conda/lib/python3.7/site-packages/xgboost/sklearn.py:797: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n  UserWarning,\n\u001b[32m[I 2022-06-05 14:15:02,787]\u001b[0m Trial 48 finished with value: 0.14424242424242426 and parameters: {'lambda': 0.026823187923384003, 'alpha': 0.8199976565974374, 'colsample_bytree': 0.9, 'subsample': 0.5, 'learning_rate': 0.018, 'max_depth': 5, 'random_state': 2020, 'min_child_weight': 150}. Best is trial 13 with value: 0.6291666666666667.\u001b[0m\n/opt/conda/lib/python3.7/site-packages/xgboost/sklearn.py:797: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n  UserWarning,\n\u001b[32m[I 2022-06-05 14:15:18,260]\u001b[0m Trial 49 finished with value: 0.3535606060606061 and parameters: {'lambda': 0.007906393593673898, 'alpha': 0.007642926997741109, 'colsample_bytree': 0.6, 'subsample': 0.7, 'learning_rate': 0.02, 'max_depth': 13, 'random_state': 2020, 'min_child_weight': 30}. Best is trial 13 with value: 0.6291666666666667.\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"Number of finished trials: 50\nBest trial: {'lambda': 0.02128232993738036, 'alpha': 0.0010978213771125056, 'colsample_bytree': 0.9, 'subsample': 0.6, 'learning_rate': 0.018, 'max_depth': 13, 'random_state': 2020, 'min_child_weight': 1}\n","output_type":"stream"}]},{"cell_type":"code","source":"#record trail history\nhist = study.trials_dataframe()\nhist.head()","metadata":{"execution":{"iopub.status.busy":"2022-06-05T14:18:30.569383Z","iopub.execute_input":"2022-06-05T14:18:30.569741Z","iopub.status.idle":"2022-06-05T14:18:30.598454Z","shell.execute_reply.started":"2022-06-05T14:18:30.569712Z","shell.execute_reply":"2022-06-05T14:18:30.597732Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"   number     value             datetime_start          datetime_complete  \\\n0       0  0.140682 2022-06-05 13:58:49.675403 2022-06-05 13:59:07.477906   \n1       1  0.157955 2022-06-05 13:59:07.481390 2022-06-05 13:59:12.053186   \n2       2  0.252197 2022-06-05 13:59:12.055169 2022-06-05 13:59:21.359961   \n3       3  0.235530 2022-06-05 13:59:21.362230 2022-06-05 13:59:29.823749   \n4       4  0.090758 2022-06-05 13:59:29.827542 2022-06-05 13:59:33.672704   \n\n                duration  params_alpha  params_colsample_bytree  \\\n0 0 days 00:00:17.802503      0.327260                      0.8   \n1 0 days 00:00:04.571796      3.087065                      0.3   \n2 0 days 00:00:09.304792      1.289423                      0.9   \n3 0 days 00:00:08.461519      0.176333                      0.4   \n4 0 days 00:00:03.845162      0.163113                      0.7   \n\n   params_lambda  params_learning_rate  params_max_depth  \\\n0       1.221240                 0.010                17   \n1       0.003549                 0.012                 5   \n2       0.199426                 0.020                13   \n3       0.010107                 0.008                 9   \n4       1.012868                 0.016                 5   \n\n   params_min_child_weight  params_random_state  params_subsample     state  \n0                      177                 2020               0.8  COMPLETE  \n1                      132                 2020               0.7  COMPLETE  \n2                       81                 2020               0.7  COMPLETE  \n3                       57                 2020               0.7  COMPLETE  \n4                      228                 2020               0.5  COMPLETE  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>number</th>\n      <th>value</th>\n      <th>datetime_start</th>\n      <th>datetime_complete</th>\n      <th>duration</th>\n      <th>params_alpha</th>\n      <th>params_colsample_bytree</th>\n      <th>params_lambda</th>\n      <th>params_learning_rate</th>\n      <th>params_max_depth</th>\n      <th>params_min_child_weight</th>\n      <th>params_random_state</th>\n      <th>params_subsample</th>\n      <th>state</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0.140682</td>\n      <td>2022-06-05 13:58:49.675403</td>\n      <td>2022-06-05 13:59:07.477906</td>\n      <td>0 days 00:00:17.802503</td>\n      <td>0.327260</td>\n      <td>0.8</td>\n      <td>1.221240</td>\n      <td>0.010</td>\n      <td>17</td>\n      <td>177</td>\n      <td>2020</td>\n      <td>0.8</td>\n      <td>COMPLETE</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>0.157955</td>\n      <td>2022-06-05 13:59:07.481390</td>\n      <td>2022-06-05 13:59:12.053186</td>\n      <td>0 days 00:00:04.571796</td>\n      <td>3.087065</td>\n      <td>0.3</td>\n      <td>0.003549</td>\n      <td>0.012</td>\n      <td>5</td>\n      <td>132</td>\n      <td>2020</td>\n      <td>0.7</td>\n      <td>COMPLETE</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>0.252197</td>\n      <td>2022-06-05 13:59:12.055169</td>\n      <td>2022-06-05 13:59:21.359961</td>\n      <td>0 days 00:00:09.304792</td>\n      <td>1.289423</td>\n      <td>0.9</td>\n      <td>0.199426</td>\n      <td>0.020</td>\n      <td>13</td>\n      <td>81</td>\n      <td>2020</td>\n      <td>0.7</td>\n      <td>COMPLETE</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>0.235530</td>\n      <td>2022-06-05 13:59:21.362230</td>\n      <td>2022-06-05 13:59:29.823749</td>\n      <td>0 days 00:00:08.461519</td>\n      <td>0.176333</td>\n      <td>0.4</td>\n      <td>0.010107</td>\n      <td>0.008</td>\n      <td>9</td>\n      <td>57</td>\n      <td>2020</td>\n      <td>0.7</td>\n      <td>COMPLETE</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>0.090758</td>\n      <td>2022-06-05 13:59:29.827542</td>\n      <td>2022-06-05 13:59:33.672704</td>\n      <td>0 days 00:00:03.845162</td>\n      <td>0.163113</td>\n      <td>0.7</td>\n      <td>1.012868</td>\n      <td>0.016</td>\n      <td>5</td>\n      <td>228</td>\n      <td>2020</td>\n      <td>0.5</td>\n      <td>COMPLETE</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"Attempt 2","metadata":{}},{"cell_type":"code","source":"# hyperparameter tuning using optuna\n# reference: https://www.kaggle.com/code/hamzaghanmi/xgboost-catboost-using-optuna/notebook?scriptVersionId=94510532\ndef objective(trial,data=X_scaled,target=y):\n    \n    train_x, test_x, train_y, test_y = train_test_split(data, target, test_size=0.33,random_state=1)\n    \n    param = {\n        'tree_method':'gpu_hist', \n        'lambda': trial.suggest_float(\"lambda\", 1e-5, 10.0, log=True),\n        'alpha': trial.suggest_float(\"alpha\", 1e-5, 10.0, log=True),\n        'colsample_bytree': trial.suggest_categorical('colsample_bytree', [0.3,0.4,0.5,0.6,0.7,0.8,0.9,1.0]),\n        'subsample': trial.suggest_categorical('subsample', [0.4,0.5,0.6,0.7,0.8,1.0]),\n        'learning_rate': trial.suggest_categorical('learning_rate', [0.008,0.01,0.012,0.014,0.016,0.018, 0.02]),\n        'n_estimators': trial.suggest_int('n_estimators',0, 1000,step = 100),\n        'max_depth': trial.suggest_categorical('max_depth', [5,7,9,11,13,15,17]),\n        'random_state': trial.suggest_categorical('random_state', [2020]),\n        'min_child_weight': trial.suggest_int('min_child_weight', 1, 300),\n    }\n    model = xgb.XGBClassifier(**param)  \n    \n    model.fit(train_x,train_y,eval_set=[(test_x,test_y)],early_stopping_rounds=100,verbose=False)\n    \n    preds = model.predict(test_x)\n    \n    accuracy = sklearn.metrics.accuracy_score(test_y, preds)\n    \n    return accuracy","metadata":{"execution":{"iopub.status.busy":"2022-06-05T14:29:15.767332Z","iopub.execute_input":"2022-06-05T14:29:15.767919Z","iopub.status.idle":"2022-06-05T14:29:15.778369Z","shell.execute_reply.started":"2022-06-05T14:29:15.767882Z","shell.execute_reply":"2022-06-05T14:29:15.777269Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"# run the study\nstudy2 = optuna.create_study(direction='maximize')\nstudy2.optimize(objective, n_trials=50)\nprint('Number of finished trials:', len(study2.trials))\nprint('Best trial:', study2.best_trial.params)\nprint('Best value:', study2.best_trial.value)","metadata":{"execution":{"iopub.status.busy":"2022-06-05T14:31:54.243315Z","iopub.execute_input":"2022-06-05T14:31:54.243890Z","iopub.status.idle":"2022-06-05T15:30:43.267942Z","shell.execute_reply.started":"2022-06-05T14:31:54.243851Z","shell.execute_reply":"2022-06-05T15:30:43.267123Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stderr","text":"\u001b[32m[I 2022-06-05 14:31:54,246]\u001b[0m A new study created in memory with name: no-name-1c7f5e74-a795-4963-b2a0-29e31189c822\u001b[0m\n/opt/conda/lib/python3.7/site-packages/xgboost/sklearn.py:797: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n  UserWarning,\n\u001b[32m[I 2022-06-05 14:32:13,294]\u001b[0m Trial 0 finished with value: 0.1762878787878788 and parameters: {'lambda': 0.0004071510472554416, 'alpha': 0.007704226736559003, 'colsample_bytree': 0.7, 'subsample': 0.6, 'learning_rate': 0.016, 'n_estimators': 900, 'max_depth': 9, 'random_state': 2020, 'min_child_weight': 161}. Best is trial 0 with value: 0.1762878787878788.\u001b[0m\n/opt/conda/lib/python3.7/site-packages/xgboost/sklearn.py:797: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n  UserWarning,\n\u001b[32m[I 2022-06-05 14:32:27,798]\u001b[0m Trial 1 finished with value: 0.22984848484848486 and parameters: {'lambda': 0.00892498687714868, 'alpha': 0.7122705504617595, 'colsample_bytree': 1.0, 'subsample': 0.4, 'learning_rate': 0.014, 'n_estimators': 300, 'max_depth': 15, 'random_state': 2020, 'min_child_weight': 64}. Best is trial 1 with value: 0.22984848484848486.\u001b[0m\n/opt/conda/lib/python3.7/site-packages/xgboost/sklearn.py:797: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n  UserWarning,\n\u001b[32m[I 2022-06-05 14:32:43,716]\u001b[0m Trial 2 finished with value: 0.09598484848484848 and parameters: {'lambda': 0.0005867235338876782, 'alpha': 0.003474757074298256, 'colsample_bytree': 0.4, 'subsample': 0.6, 'learning_rate': 0.008, 'n_estimators': 800, 'max_depth': 11, 'random_state': 2020, 'min_child_weight': 244}. Best is trial 1 with value: 0.22984848484848486.\u001b[0m\n/opt/conda/lib/python3.7/site-packages/xgboost/sklearn.py:797: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n  UserWarning,\n\u001b[32m[I 2022-06-05 14:33:40,081]\u001b[0m Trial 3 finished with value: 0.4018181818181818 and parameters: {'lambda': 0.002525636922840961, 'alpha': 5.7021681534056365e-05, 'colsample_bytree': 0.8, 'subsample': 0.4, 'learning_rate': 0.016, 'n_estimators': 800, 'max_depth': 15, 'random_state': 2020, 'min_child_weight': 21}. Best is trial 3 with value: 0.4018181818181818.\u001b[0m\n/opt/conda/lib/python3.7/site-packages/xgboost/sklearn.py:797: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n  UserWarning,\n\u001b[32m[I 2022-06-05 14:33:42,123]\u001b[0m Trial 4 finished with value: 0.022954545454545453 and parameters: {'lambda': 0.002492771091471992, 'alpha': 0.14316261146170434, 'colsample_bytree': 0.4, 'subsample': 0.4, 'learning_rate': 0.01, 'n_estimators': 500, 'max_depth': 13, 'random_state': 2020, 'min_child_weight': 291}. Best is trial 3 with value: 0.4018181818181818.\u001b[0m\n/opt/conda/lib/python3.7/site-packages/xgboost/sklearn.py:797: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n  UserWarning,\n\u001b[32m[I 2022-06-05 14:33:48,497]\u001b[0m Trial 5 finished with value: 0.10681818181818181 and parameters: {'lambda': 4.002935635207666, 'alpha': 0.21749441065697833, 'colsample_bytree': 0.6, 'subsample': 0.4, 'learning_rate': 0.02, 'n_estimators': 300, 'max_depth': 5, 'random_state': 2020, 'min_child_weight': 152}. Best is trial 3 with value: 0.4018181818181818.\u001b[0m\n/opt/conda/lib/python3.7/site-packages/xgboost/sklearn.py:797: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n  UserWarning,\n\u001b[32m[I 2022-06-05 14:34:07,076]\u001b[0m Trial 6 finished with value: 0.13075757575757577 and parameters: {'lambda': 3.0920353314287863, 'alpha': 0.01973707208038214, 'colsample_bytree': 0.9, 'subsample': 0.5, 'learning_rate': 0.014, 'n_estimators': 500, 'max_depth': 15, 'random_state': 2020, 'min_child_weight': 171}. Best is trial 3 with value: 0.4018181818181818.\u001b[0m\n/opt/conda/lib/python3.7/site-packages/xgboost/sklearn.py:797: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n  UserWarning,\n\u001b[32m[I 2022-06-05 14:34:09,326]\u001b[0m Trial 7 finished with value: 0.07340909090909091 and parameters: {'lambda': 0.0032469498818579797, 'alpha': 2.611542058715887, 'colsample_bytree': 0.9, 'subsample': 0.6, 'learning_rate': 0.008, 'n_estimators': 100, 'max_depth': 11, 'random_state': 2020, 'min_child_weight': 274}. Best is trial 3 with value: 0.4018181818181818.\u001b[0m\n/opt/conda/lib/python3.7/site-packages/xgboost/sklearn.py:797: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n  UserWarning,\n\u001b[32m[I 2022-06-05 14:34:30,783]\u001b[0m Trial 8 finished with value: 0.12431818181818181 and parameters: {'lambda': 0.053239709616874256, 'alpha': 0.01885502951334402, 'colsample_bytree': 0.7, 'subsample': 0.5, 'learning_rate': 0.016, 'n_estimators': 600, 'max_depth': 15, 'random_state': 2020, 'min_child_weight': 175}. Best is trial 3 with value: 0.4018181818181818.\u001b[0m\n/opt/conda/lib/python3.7/site-packages/xgboost/sklearn.py:797: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n  UserWarning,\n\u001b[32m[I 2022-06-05 14:34:48,552]\u001b[0m Trial 9 finished with value: 0.14954545454545454 and parameters: {'lambda': 3.692581063873889e-05, 'alpha': 0.00012229768801692617, 'colsample_bytree': 0.9, 'subsample': 0.8, 'learning_rate': 0.008, 'n_estimators': 700, 'max_depth': 11, 'random_state': 2020, 'min_child_weight': 224}. Best is trial 3 with value: 0.4018181818181818.\u001b[0m\n/opt/conda/lib/python3.7/site-packages/xgboost/sklearn.py:797: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n  UserWarning,\n\u001b[32m[I 2022-06-05 14:35:55,540]\u001b[0m Trial 10 finished with value: 0.4517424242424242 and parameters: {'lambda': 0.38689761647373805, 'alpha': 1.8499687572448376e-05, 'colsample_bytree': 0.8, 'subsample': 1.0, 'learning_rate': 0.012, 'n_estimators': 1000, 'max_depth': 7, 'random_state': 2020, 'min_child_weight': 19}. Best is trial 10 with value: 0.4517424242424242.\u001b[0m\n/opt/conda/lib/python3.7/site-packages/xgboost/sklearn.py:797: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n  UserWarning,\n\u001b[32m[I 2022-06-05 14:37:37,609]\u001b[0m Trial 11 finished with value: 0.5385606060606061 and parameters: {'lambda': 0.1539649527025812, 'alpha': 1.1140306491597999e-05, 'colsample_bytree': 0.8, 'subsample': 1.0, 'learning_rate': 0.012, 'n_estimators': 1000, 'max_depth': 7, 'random_state': 2020, 'min_child_weight': 5}. Best is trial 11 with value: 0.5385606060606061.\u001b[0m\n/opt/conda/lib/python3.7/site-packages/xgboost/sklearn.py:797: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n  UserWarning,\n\u001b[32m[I 2022-06-05 14:38:11,213]\u001b[0m Trial 12 finished with value: 0.31765151515151513 and parameters: {'lambda': 0.17116123266216238, 'alpha': 1.0923467414753284e-05, 'colsample_bytree': 0.8, 'subsample': 1.0, 'learning_rate': 0.012, 'n_estimators': 1000, 'max_depth': 7, 'random_state': 2020, 'min_child_weight': 76}. Best is trial 11 with value: 0.5385606060606061.\u001b[0m\n/opt/conda/lib/python3.7/site-packages/xgboost/sklearn.py:797: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n  UserWarning,\n\u001b[32m[I 2022-06-05 14:39:57,577]\u001b[0m Trial 13 finished with value: 0.5503030303030303 and parameters: {'lambda': 0.32537535648982063, 'alpha': 0.00038552165265691424, 'colsample_bytree': 0.8, 'subsample': 1.0, 'learning_rate': 0.012, 'n_estimators': 1000, 'max_depth': 7, 'random_state': 2020, 'min_child_weight': 4}. Best is trial 13 with value: 0.5503030303030303.\u001b[0m\n/opt/conda/lib/python3.7/site-packages/xgboost/sklearn.py:797: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n  UserWarning,\n\u001b[32m[I 2022-06-05 14:40:25,289]\u001b[0m Trial 14 finished with value: 0.24507575757575759 and parameters: {'lambda': 0.41975979535527047, 'alpha': 0.0004250638101617871, 'colsample_bytree': 0.5, 'subsample': 0.7, 'learning_rate': 0.012, 'n_estimators': 1000, 'max_depth': 7, 'random_state': 2020, 'min_child_weight': 84}. Best is trial 13 with value: 0.5503030303030303.\u001b[0m\n/opt/conda/lib/python3.7/site-packages/xgboost/sklearn.py:797: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n  UserWarning,\n\u001b[32m[I 2022-06-05 14:43:37,437]\u001b[0m Trial 15 finished with value: 0.5964393939393939 and parameters: {'lambda': 0.026145569490671983, 'alpha': 0.0008936138719761097, 'colsample_bytree': 0.8, 'subsample': 1.0, 'learning_rate': 0.018, 'n_estimators': 800, 'max_depth': 17, 'random_state': 2020, 'min_child_weight': 5}. Best is trial 15 with value: 0.5964393939393939.\u001b[0m\n/opt/conda/lib/python3.7/site-packages/xgboost/sklearn.py:797: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n  UserWarning,\n\u001b[32m[I 2022-06-05 14:44:32,784]\u001b[0m Trial 16 finished with value: 0.21378787878787878 and parameters: {'lambda': 0.032427817884687245, 'alpha': 0.0009176027162218752, 'colsample_bytree': 0.3, 'subsample': 1.0, 'learning_rate': 0.018, 'n_estimators': 800, 'max_depth': 17, 'random_state': 2020, 'min_child_weight': 109}. Best is trial 15 with value: 0.5964393939393939.\u001b[0m\n/opt/conda/lib/python3.7/site-packages/xgboost/sklearn.py:797: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n  UserWarning,\n\u001b[32m[I 2022-06-05 14:45:38,490]\u001b[0m Trial 17 finished with value: 0.38545454545454544 and parameters: {'lambda': 0.9996559199443753, 'alpha': 0.0011123454449877162, 'colsample_bytree': 0.8, 'subsample': 1.0, 'learning_rate': 0.018, 'n_estimators': 700, 'max_depth': 17, 'random_state': 2020, 'min_child_weight': 46}. Best is trial 15 with value: 0.5964393939393939.\u001b[0m\n/opt/conda/lib/python3.7/site-packages/xgboost/sklearn.py:797: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n  UserWarning,\n\u001b[32m[I 2022-06-05 14:45:38,527]\u001b[0m Trial 18 finished with value: 0.026136363636363635 and parameters: {'lambda': 0.04610103704845506, 'alpha': 0.00027121096995596497, 'colsample_bytree': 0.5, 'subsample': 0.7, 'learning_rate': 0.018, 'n_estimators': 0, 'max_depth': 17, 'random_state': 2020, 'min_child_weight': 117}. Best is trial 15 with value: 0.5964393939393939.\u001b[0m\n/opt/conda/lib/python3.7/site-packages/xgboost/sklearn.py:797: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n  UserWarning,\n\u001b[32m[I 2022-06-05 14:46:11,127]\u001b[0m Trial 19 finished with value: 0.3776515151515151 and parameters: {'lambda': 2.885657866764142e-05, 'alpha': 0.0031460445346387102, 'colsample_bytree': 1.0, 'subsample': 0.8, 'learning_rate': 0.02, 'n_estimators': 900, 'max_depth': 5, 'random_state': 2020, 'min_child_weight': 46}. Best is trial 15 with value: 0.5964393939393939.\u001b[0m\n/opt/conda/lib/python3.7/site-packages/xgboost/sklearn.py:797: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n  UserWarning,\n\u001b[32m[I 2022-06-05 14:47:21,880]\u001b[0m Trial 20 finished with value: 0.5074242424242424 and parameters: {'lambda': 8.099709781547237, 'alpha': 8.27041718904638e-05, 'colsample_bytree': 0.6, 'subsample': 1.0, 'learning_rate': 0.01, 'n_estimators': 300, 'max_depth': 9, 'random_state': 2020, 'min_child_weight': 1}. Best is trial 15 with value: 0.5964393939393939.\u001b[0m\n/opt/conda/lib/python3.7/site-packages/xgboost/sklearn.py:797: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n  UserWarning,\n\u001b[32m[I 2022-06-05 14:49:16,802]\u001b[0m Trial 21 finished with value: 0.5838636363636364 and parameters: {'lambda': 0.08918479980353267, 'alpha': 3.228278878118664e-05, 'colsample_bytree': 0.8, 'subsample': 1.0, 'learning_rate': 0.012, 'n_estimators': 900, 'max_depth': 7, 'random_state': 2020, 'min_child_weight': 1}. Best is trial 15 with value: 0.5964393939393939.\u001b[0m\n/opt/conda/lib/python3.7/site-packages/xgboost/sklearn.py:797: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n  UserWarning,\n\u001b[32m[I 2022-06-05 14:50:03,185]\u001b[0m Trial 22 finished with value: 0.39454545454545453 and parameters: {'lambda': 0.012609570558351404, 'alpha': 4.20077274831763e-05, 'colsample_bytree': 0.8, 'subsample': 1.0, 'learning_rate': 0.012, 'n_estimators': 900, 'max_depth': 7, 'random_state': 2020, 'min_child_weight': 37}. Best is trial 15 with value: 0.5964393939393939.\u001b[0m\n/opt/conda/lib/python3.7/site-packages/xgboost/sklearn.py:797: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n  UserWarning,\n\u001b[32m[I 2022-06-05 14:50:24,351]\u001b[0m Trial 23 finished with value: 0.25166666666666665 and parameters: {'lambda': 0.9837825004583021, 'alpha': 0.0005595506189388805, 'colsample_bytree': 0.8, 'subsample': 1.0, 'learning_rate': 0.018, 'n_estimators': 700, 'max_depth': 13, 'random_state': 2020, 'min_child_weight': 121}. Best is trial 15 with value: 0.5964393939393939.\u001b[0m\n/opt/conda/lib/python3.7/site-packages/xgboost/sklearn.py:797: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n  UserWarning,\n\u001b[32m[I 2022-06-05 14:51:45,215]\u001b[0m Trial 24 finished with value: 0.29787878787878785 and parameters: {'lambda': 0.14195365237978974, 'alpha': 0.00019519473876363288, 'colsample_bytree': 0.3, 'subsample': 1.0, 'learning_rate': 0.012, 'n_estimators': 900, 'max_depth': 17, 'random_state': 2020, 'min_child_weight': 27}. Best is trial 15 with value: 0.5964393939393939.\u001b[0m\n/opt/conda/lib/python3.7/site-packages/xgboost/sklearn.py:797: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n  UserWarning,\n\u001b[32m[I 2022-06-05 14:52:22,101]\u001b[0m Trial 25 finished with value: 0.3596969696969697 and parameters: {'lambda': 0.011771002656085432, 'alpha': 0.0021417861696193504, 'colsample_bytree': 0.8, 'subsample': 1.0, 'learning_rate': 0.012, 'n_estimators': 800, 'max_depth': 7, 'random_state': 2020, 'min_child_weight': 53}. Best is trial 15 with value: 0.5964393939393939.\u001b[0m\n/opt/conda/lib/python3.7/site-packages/xgboost/sklearn.py:797: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n  UserWarning,\n\u001b[32m[I 2022-06-05 14:52:38,700]\u001b[0m Trial 26 finished with value: 0.2902272727272727 and parameters: {'lambda': 0.07225869616541343, 'alpha': 2.8235644112874298e-05, 'colsample_bytree': 0.8, 'subsample': 1.0, 'learning_rate': 0.018, 'n_estimators': 500, 'max_depth': 7, 'random_state': 2020, 'min_child_weight': 89}. Best is trial 15 with value: 0.5964393939393939.\u001b[0m\n/opt/conda/lib/python3.7/site-packages/xgboost/sklearn.py:797: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n  UserWarning,\n\u001b[32m[I 2022-06-05 14:57:30,531]\u001b[0m Trial 27 finished with value: 0.6287878787878788 and parameters: {'lambda': 0.8074163172825457, 'alpha': 0.00015547907410411112, 'colsample_bytree': 0.8, 'subsample': 0.7, 'learning_rate': 0.012, 'n_estimators': 600, 'max_depth': 17, 'random_state': 2020, 'min_child_weight': 2}. Best is trial 27 with value: 0.6287878787878788.\u001b[0m\n/opt/conda/lib/python3.7/site-packages/xgboost/sklearn.py:797: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n  UserWarning,\n\u001b[32m[I 2022-06-05 14:58:42,577]\u001b[0m Trial 28 finished with value: 0.419469696969697 and parameters: {'lambda': 1.2695009453314485, 'alpha': 0.00010040375855033318, 'colsample_bytree': 0.8, 'subsample': 0.7, 'learning_rate': 0.014, 'n_estimators': 600, 'max_depth': 17, 'random_state': 2020, 'min_child_weight': 27}. Best is trial 27 with value: 0.6287878787878788.\u001b[0m\n/opt/conda/lib/python3.7/site-packages/xgboost/sklearn.py:797: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n  UserWarning,\n\u001b[32m[I 2022-06-05 14:58:56,781]\u001b[0m Trial 29 finished with value: 0.15295454545454545 and parameters: {'lambda': 0.0002960944552480792, 'alpha': 0.011903039746452782, 'colsample_bytree': 0.6, 'subsample': 0.7, 'learning_rate': 0.01, 'n_estimators': 600, 'max_depth': 9, 'random_state': 2020, 'min_child_weight': 190}. Best is trial 27 with value: 0.6287878787878788.\u001b[0m\n/opt/conda/lib/python3.7/site-packages/xgboost/sklearn.py:797: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n  UserWarning,\n\u001b[32m[I 2022-06-05 14:59:30,997]\u001b[0m Trial 30 finished with value: 0.2972727272727273 and parameters: {'lambda': 0.02411409322691103, 'alpha': 0.041953418826426954, 'colsample_bytree': 0.7, 'subsample': 0.7, 'learning_rate': 0.02, 'n_estimators': 400, 'max_depth': 17, 'random_state': 2020, 'min_child_weight': 60}. Best is trial 27 with value: 0.6287878787878788.\u001b[0m\n/opt/conda/lib/python3.7/site-packages/xgboost/sklearn.py:797: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n  UserWarning,\n\u001b[32m[I 2022-06-05 15:07:40,496]\u001b[0m Trial 31 finished with value: 0.6446212121212122 and parameters: {'lambda': 0.35573812114503994, 'alpha': 0.0002588872721826578, 'colsample_bytree': 0.8, 'subsample': 0.5, 'learning_rate': 0.012, 'n_estimators': 900, 'max_depth': 17, 'random_state': 2020, 'min_child_weight': 1}. Best is trial 31 with value: 0.6446212121212122.\u001b[0m\n/opt/conda/lib/python3.7/site-packages/xgboost/sklearn.py:797: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n  UserWarning,\n\u001b[32m[I 2022-06-05 15:12:25,625]\u001b[0m Trial 32 finished with value: 0.6082575757575758 and parameters: {'lambda': 1.8910064632443546, 'alpha': 0.001436413412409568, 'colsample_bytree': 1.0, 'subsample': 0.5, 'learning_rate': 0.012, 'n_estimators': 900, 'max_depth': 17, 'random_state': 2020, 'min_child_weight': 3}. Best is trial 31 with value: 0.6446212121212122.\u001b[0m\n/opt/conda/lib/python3.7/site-packages/xgboost/sklearn.py:797: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n  UserWarning,\n\u001b[32m[I 2022-06-05 15:13:35,482]\u001b[0m Trial 33 finished with value: 0.3577272727272727 and parameters: {'lambda': 2.313113438640646, 'alpha': 0.005894616439772852, 'colsample_bytree': 0.4, 'subsample': 0.5, 'learning_rate': 0.012, 'n_estimators': 700, 'max_depth': 17, 'random_state': 2020, 'min_child_weight': 24}. Best is trial 31 with value: 0.6446212121212122.\u001b[0m\n/opt/conda/lib/python3.7/site-packages/xgboost/sklearn.py:797: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n  UserWarning,\n\u001b[32m[I 2022-06-05 15:14:42,162]\u001b[0m Trial 34 finished with value: 0.3071969696969697 and parameters: {'lambda': 7.6185354753131564, 'alpha': 0.0014987856872906299, 'colsample_bytree': 1.0, 'subsample': 0.5, 'learning_rate': 0.012, 'n_estimators': 800, 'max_depth': 17, 'random_state': 2020, 'min_child_weight': 61}. Best is trial 31 with value: 0.6446212121212122.\u001b[0m\n/opt/conda/lib/python3.7/site-packages/xgboost/sklearn.py:797: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n  UserWarning,\n\u001b[32m[I 2022-06-05 15:15:55,222]\u001b[0m Trial 35 finished with value: 0.37962121212121214 and parameters: {'lambda': 0.464795295336498, 'alpha': 0.005064008250838265, 'colsample_bytree': 1.0, 'subsample': 0.5, 'learning_rate': 0.018, 'n_estimators': 800, 'max_depth': 17, 'random_state': 2020, 'min_child_weight': 36}. Best is trial 31 with value: 0.6446212121212122.\u001b[0m\n/opt/conda/lib/python3.7/site-packages/xgboost/sklearn.py:797: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n  UserWarning,\n\u001b[32m[I 2022-06-05 15:17:19,820]\u001b[0m Trial 36 finished with value: 0.47674242424242425 and parameters: {'lambda': 1.5684571412258914, 'alpha': 0.0006508083080704245, 'colsample_bytree': 1.0, 'subsample': 0.5, 'learning_rate': 0.016, 'n_estimators': 600, 'max_depth': 17, 'random_state': 2020, 'min_child_weight': 15}. Best is trial 31 with value: 0.6446212121212122.\u001b[0m\n/opt/conda/lib/python3.7/site-packages/xgboost/sklearn.py:797: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n  UserWarning,\n\u001b[32m[I 2022-06-05 15:18:30,606]\u001b[0m Trial 37 finished with value: 0.29204545454545455 and parameters: {'lambda': 0.6983499794019448, 'alpha': 0.0002085629969875733, 'colsample_bytree': 1.0, 'subsample': 0.6, 'learning_rate': 0.014, 'n_estimators': 900, 'max_depth': 17, 'random_state': 2020, 'min_child_weight': 75}. Best is trial 31 with value: 0.6446212121212122.\u001b[0m\n/opt/conda/lib/python3.7/site-packages/xgboost/sklearn.py:797: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n  UserWarning,\n\u001b[32m[I 2022-06-05 15:19:00,981]\u001b[0m Trial 38 finished with value: 0.2847727272727273 and parameters: {'lambda': 0.00087142861296062, 'alpha': 8.114400958686726, 'colsample_bytree': 0.4, 'subsample': 0.5, 'learning_rate': 0.008, 'n_estimators': 800, 'max_depth': 5, 'random_state': 2020, 'min_child_weight': 39}. Best is trial 31 with value: 0.6446212121212122.\u001b[0m\n/opt/conda/lib/python3.7/site-packages/xgboost/sklearn.py:797: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n  UserWarning,\n\u001b[32m[I 2022-06-05 15:19:13,245]\u001b[0m Trial 39 finished with value: 0.18840909090909091 and parameters: {'lambda': 3.6289183036919925, 'alpha': 0.0022495293897153994, 'colsample_bytree': 0.7, 'subsample': 0.4, 'learning_rate': 0.016, 'n_estimators': 400, 'max_depth': 13, 'random_state': 2020, 'min_child_weight': 95}. Best is trial 31 with value: 0.6446212121212122.\u001b[0m\n/opt/conda/lib/python3.7/site-packages/xgboost/sklearn.py:797: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n  UserWarning,\n\u001b[32m[I 2022-06-05 15:20:28,178]\u001b[0m Trial 40 finished with value: 0.3765151515151515 and parameters: {'lambda': 0.0031437042230793998, 'alpha': 0.11957005123487399, 'colsample_bytree': 0.5, 'subsample': 0.5, 'learning_rate': 0.012, 'n_estimators': 700, 'max_depth': 17, 'random_state': 2020, 'min_child_weight': 18}. Best is trial 31 with value: 0.6446212121212122.\u001b[0m\n/opt/conda/lib/python3.7/site-packages/xgboost/sklearn.py:797: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n  UserWarning,\n\u001b[32m[I 2022-06-05 15:23:38,978]\u001b[0m Trial 41 finished with value: 0.6013636363636363 and parameters: {'lambda': 0.08929227636178136, 'alpha': 4.77365001385838e-05, 'colsample_bytree': 0.8, 'subsample': 0.8, 'learning_rate': 0.012, 'n_estimators': 900, 'max_depth': 11, 'random_state': 2020, 'min_child_weight': 4}. Best is trial 31 with value: 0.6446212121212122.\u001b[0m\n/opt/conda/lib/python3.7/site-packages/xgboost/sklearn.py:797: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n  UserWarning,\n\u001b[32m[I 2022-06-05 15:25:31,985]\u001b[0m Trial 42 finished with value: 0.5246969696969697 and parameters: {'lambda': 0.22887877547757854, 'alpha': 0.00015447763305161593, 'colsample_bytree': 0.8, 'subsample': 0.8, 'learning_rate': 0.012, 'n_estimators': 900, 'max_depth': 11, 'random_state': 2020, 'min_child_weight': 11}. Best is trial 31 with value: 0.6446212121212122.\u001b[0m\n/opt/conda/lib/python3.7/site-packages/xgboost/sklearn.py:797: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n  UserWarning,\n\u001b[32m[I 2022-06-05 15:25:55,753]\u001b[0m Trial 43 finished with value: 0.23196969696969696 and parameters: {'lambda': 0.00619330071038982, 'alpha': 6.606264625302888e-05, 'colsample_bytree': 0.9, 'subsample': 0.8, 'learning_rate': 0.012, 'n_estimators': 800, 'max_depth': 11, 'random_state': 2020, 'min_child_weight': 135}. Best is trial 31 with value: 0.6446212121212122.\u001b[0m\n/opt/conda/lib/python3.7/site-packages/xgboost/sklearn.py:797: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n  UserWarning,\n\u001b[32m[I 2022-06-05 15:26:58,629]\u001b[0m Trial 44 finished with value: 0.42045454545454547 and parameters: {'lambda': 0.023801476197655033, 'alpha': 0.00042114040371219483, 'colsample_bytree': 0.8, 'subsample': 0.8, 'learning_rate': 0.012, 'n_estimators': 1000, 'max_depth': 11, 'random_state': 2020, 'min_child_weight': 30}. Best is trial 31 with value: 0.6446212121212122.\u001b[0m\n/opt/conda/lib/python3.7/site-packages/xgboost/sklearn.py:797: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n  UserWarning,\n\u001b[32m[I 2022-06-05 15:27:30,377]\u001b[0m Trial 45 finished with value: 0.12189393939393939 and parameters: {'lambda': 0.1168874911029287, 'alpha': 0.0008751469858022182, 'colsample_bytree': 0.8, 'subsample': 0.6, 'learning_rate': 0.01, 'n_estimators': 900, 'max_depth': 15, 'random_state': 2020, 'min_child_weight': 215}. Best is trial 31 with value: 0.6446212121212122.\u001b[0m\n/opt/conda/lib/python3.7/site-packages/xgboost/sklearn.py:797: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n  UserWarning,\n\u001b[32m[I 2022-06-05 15:28:00,433]\u001b[0m Trial 46 finished with value: 0.2834090909090909 and parameters: {'lambda': 0.6028584265146354, 'alpha': 2.303667751883575e-05, 'colsample_bytree': 0.3, 'subsample': 0.4, 'learning_rate': 0.008, 'n_estimators': 700, 'max_depth': 11, 'random_state': 2020, 'min_child_weight': 16}. Best is trial 31 with value: 0.6446212121212122.\u001b[0m\n/opt/conda/lib/python3.7/site-packages/xgboost/sklearn.py:797: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n  UserWarning,\n\u001b[32m[I 2022-06-05 15:28:13,308]\u001b[0m Trial 47 finished with value: 0.07287878787878788 and parameters: {'lambda': 0.2393818760404167, 'alpha': 6.281910042113646e-05, 'colsample_bytree': 0.8, 'subsample': 0.5, 'learning_rate': 0.012, 'n_estimators': 200, 'max_depth': 17, 'random_state': 2020, 'min_child_weight': 279}. Best is trial 31 with value: 0.6446212121212122.\u001b[0m\n/opt/conda/lib/python3.7/site-packages/xgboost/sklearn.py:797: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n  UserWarning,\n\u001b[32m[I 2022-06-05 15:30:16,059]\u001b[0m Trial 48 finished with value: 0.5771212121212121 and parameters: {'lambda': 2.356782552353266, 'alpha': 0.000125425705549807, 'colsample_bytree': 1.0, 'subsample': 0.8, 'learning_rate': 0.02, 'n_estimators': 1000, 'max_depth': 9, 'random_state': 2020, 'min_child_weight': 9}. Best is trial 31 with value: 0.6446212121212122.\u001b[0m\n/opt/conda/lib/python3.7/site-packages/xgboost/sklearn.py:797: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n  UserWarning,\n\u001b[32m[I 2022-06-05 15:30:43,251]\u001b[0m Trial 49 finished with value: 0.289469696969697 and parameters: {'lambda': 0.03521733901103625, 'alpha': 0.0015280483462660561, 'colsample_bytree': 0.9, 'subsample': 0.7, 'learning_rate': 0.014, 'n_estimators': 500, 'max_depth': 15, 'random_state': 2020, 'min_child_weight': 69}. Best is trial 31 with value: 0.6446212121212122.\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"Number of finished trials: 50\nBest trial: {'lambda': 0.35573812114503994, 'alpha': 0.0002588872721826578, 'colsample_bytree': 0.8, 'subsample': 0.5, 'learning_rate': 0.012, 'n_estimators': 900, 'max_depth': 17, 'random_state': 2020, 'min_child_weight': 1}\nBest value: 0.6446212121212122\n","output_type":"stream"}]},{"cell_type":"code","source":"print('Best trial:', study2.best_trial.params)\n#record trail history\nhist = study2.trials_dataframe()\nhist.head()","metadata":{"execution":{"iopub.status.busy":"2022-06-05T15:43:49.439756Z","iopub.execute_input":"2022-06-05T15:43:49.440184Z","iopub.status.idle":"2022-06-05T15:43:49.470869Z","shell.execute_reply.started":"2022-06-05T15:43:49.440148Z","shell.execute_reply":"2022-06-05T15:43:49.469577Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"Best trial: {'lambda': 0.35573812114503994, 'alpha': 0.0002588872721826578, 'colsample_bytree': 0.8, 'subsample': 0.5, 'learning_rate': 0.012, 'n_estimators': 900, 'max_depth': 17, 'random_state': 2020, 'min_child_weight': 1}\n","output_type":"stream"},{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"   number     value             datetime_start          datetime_complete  \\\n0       0  0.140682 2022-06-05 13:58:49.675403 2022-06-05 13:59:07.477906   \n1       1  0.157955 2022-06-05 13:59:07.481390 2022-06-05 13:59:12.053186   \n2       2  0.252197 2022-06-05 13:59:12.055169 2022-06-05 13:59:21.359961   \n3       3  0.235530 2022-06-05 13:59:21.362230 2022-06-05 13:59:29.823749   \n4       4  0.090758 2022-06-05 13:59:29.827542 2022-06-05 13:59:33.672704   \n\n                duration  params_alpha  params_colsample_bytree  \\\n0 0 days 00:00:17.802503      0.327260                      0.8   \n1 0 days 00:00:04.571796      3.087065                      0.3   \n2 0 days 00:00:09.304792      1.289423                      0.9   \n3 0 days 00:00:08.461519      0.176333                      0.4   \n4 0 days 00:00:03.845162      0.163113                      0.7   \n\n   params_lambda  params_learning_rate  params_max_depth  \\\n0       1.221240                 0.010                17   \n1       0.003549                 0.012                 5   \n2       0.199426                 0.020                13   \n3       0.010107                 0.008                 9   \n4       1.012868                 0.016                 5   \n\n   params_min_child_weight  params_random_state  params_subsample     state  \n0                      177                 2020               0.8  COMPLETE  \n1                      132                 2020               0.7  COMPLETE  \n2                       81                 2020               0.7  COMPLETE  \n3                       57                 2020               0.7  COMPLETE  \n4                      228                 2020               0.5  COMPLETE  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>number</th>\n      <th>value</th>\n      <th>datetime_start</th>\n      <th>datetime_complete</th>\n      <th>duration</th>\n      <th>params_alpha</th>\n      <th>params_colsample_bytree</th>\n      <th>params_lambda</th>\n      <th>params_learning_rate</th>\n      <th>params_max_depth</th>\n      <th>params_min_child_weight</th>\n      <th>params_random_state</th>\n      <th>params_subsample</th>\n      <th>state</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0.140682</td>\n      <td>2022-06-05 13:58:49.675403</td>\n      <td>2022-06-05 13:59:07.477906</td>\n      <td>0 days 00:00:17.802503</td>\n      <td>0.327260</td>\n      <td>0.8</td>\n      <td>1.221240</td>\n      <td>0.010</td>\n      <td>17</td>\n      <td>177</td>\n      <td>2020</td>\n      <td>0.8</td>\n      <td>COMPLETE</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>0.157955</td>\n      <td>2022-06-05 13:59:07.481390</td>\n      <td>2022-06-05 13:59:12.053186</td>\n      <td>0 days 00:00:04.571796</td>\n      <td>3.087065</td>\n      <td>0.3</td>\n      <td>0.003549</td>\n      <td>0.012</td>\n      <td>5</td>\n      <td>132</td>\n      <td>2020</td>\n      <td>0.7</td>\n      <td>COMPLETE</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>0.252197</td>\n      <td>2022-06-05 13:59:12.055169</td>\n      <td>2022-06-05 13:59:21.359961</td>\n      <td>0 days 00:00:09.304792</td>\n      <td>1.289423</td>\n      <td>0.9</td>\n      <td>0.199426</td>\n      <td>0.020</td>\n      <td>13</td>\n      <td>81</td>\n      <td>2020</td>\n      <td>0.7</td>\n      <td>COMPLETE</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>0.235530</td>\n      <td>2022-06-05 13:59:21.362230</td>\n      <td>2022-06-05 13:59:29.823749</td>\n      <td>0 days 00:00:08.461519</td>\n      <td>0.176333</td>\n      <td>0.4</td>\n      <td>0.010107</td>\n      <td>0.008</td>\n      <td>9</td>\n      <td>57</td>\n      <td>2020</td>\n      <td>0.7</td>\n      <td>COMPLETE</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>0.090758</td>\n      <td>2022-06-05 13:59:29.827542</td>\n      <td>2022-06-05 13:59:33.672704</td>\n      <td>0 days 00:00:03.845162</td>\n      <td>0.163113</td>\n      <td>0.7</td>\n      <td>1.012868</td>\n      <td>0.016</td>\n      <td>5</td>\n      <td>228</td>\n      <td>2020</td>\n      <td>0.5</td>\n      <td>COMPLETE</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"optuna.visualization.plot_optimization_history(study2)","metadata":{"execution":{"iopub.status.busy":"2022-06-05T15:46:03.653739Z","iopub.execute_input":"2022-06-05T15:46:03.654163Z","iopub.status.idle":"2022-06-05T15:46:03.761312Z","shell.execute_reply.started":"2022-06-05T15:46:03.654128Z","shell.execute_reply":"2022-06-05T15:46:03.760597Z"},"trusted":true},"execution_count":18,"outputs":[{"output_type":"display_data","data":{"text/html":"        <script type=\"text/javascript\">\n        window.PlotlyConfig = {MathJaxConfig: 'local'};\n        if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n        if (typeof require !== 'undefined') {\n        require.undef(\"plotly\");\n        requirejs.config({\n            paths: {\n                'plotly': ['https://cdn.plot.ly/plotly-2.12.1.min']\n            }\n        });\n        require(['plotly'], function(Plotly) {\n            window._Plotly = Plotly;\n        });\n        }\n        </script>\n        "},"metadata":{}},{"output_type":"display_data","data":{"text/html":"<div>                            <div id=\"8cdb3bde-c90f-405f-8a2c-c1b43573dd72\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"8cdb3bde-c90f-405f-8a2c-c1b43573dd72\")) {                    Plotly.newPlot(                        \"8cdb3bde-c90f-405f-8a2c-c1b43573dd72\",                        [{\"mode\":\"markers\",\"name\":\"Objective Value\",\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49],\"y\":[0.14068181818181819,0.15795454545454546,0.2521969696969697,0.23553030303030303,0.09075757575757576,0.1784090909090909,0.11916666666666667,0.20666666666666667,0.06477272727272727,0.22984848484848486,0.546969696969697,0.5475757575757576,0.3468181818181818,0.6291666666666667,0.5417424242424242,0.2362121212121212,0.3162121212121212,0.2959090909090909,0.18606060606060607,0.10833333333333334,0.3275757575757576,0.5281818181818182,0.31696969696969696,0.39704545454545453,0.28204545454545454,0.2103030303030303,0.26386363636363636,0.37454545454545457,0.11492424242424243,0.09295454545454546,0.10621212121212122,0.5011363636363636,0.5720454545454545,0.35,0.32242424242424245,0.2887878787878788,0.34424242424242424,0.18924242424242424,0.20787878787878789,0.24856060606060607,0.1878030303030303,0.5413636363636364,0.3993181818181818,0.3934848484848485,0.5320454545454546,0.31431818181818183,0.15075757575757576,0.2290151515151515,0.14424242424242426,0.3535606060606061],\"type\":\"scatter\"},{\"name\":\"Best Value\",\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49],\"y\":[0.14068181818181819,0.15795454545454546,0.2521969696969697,0.2521969696969697,0.2521969696969697,0.2521969696969697,0.2521969696969697,0.2521969696969697,0.2521969696969697,0.2521969696969697,0.546969696969697,0.5475757575757576,0.5475757575757576,0.6291666666666667,0.6291666666666667,0.6291666666666667,0.6291666666666667,0.6291666666666667,0.6291666666666667,0.6291666666666667,0.6291666666666667,0.6291666666666667,0.6291666666666667,0.6291666666666667,0.6291666666666667,0.6291666666666667,0.6291666666666667,0.6291666666666667,0.6291666666666667,0.6291666666666667,0.6291666666666667,0.6291666666666667,0.6291666666666667,0.6291666666666667,0.6291666666666667,0.6291666666666667,0.6291666666666667,0.6291666666666667,0.6291666666666667,0.6291666666666667,0.6291666666666667,0.6291666666666667,0.6291666666666667,0.6291666666666667,0.6291666666666667,0.6291666666666667,0.6291666666666667,0.6291666666666667,0.6291666666666667,0.6291666666666667],\"type\":\"scatter\"}],                        {\"title\":{\"text\":\"Optimization History Plot\"},\"xaxis\":{\"title\":{\"text\":\"#Trials\"}},\"yaxis\":{\"title\":{\"text\":\"Objective Value\"}},\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}}},                        {\"responsive\": true}                    ).then(function(){\n                            \nvar gd = document.getElementById('8cdb3bde-c90f-405f-8a2c-c1b43573dd72');\nvar x = new MutationObserver(function (mutations, observer) {{\n        var display = window.getComputedStyle(gd).display;\n        if (!display || display === 'none') {{\n            console.log([gd, 'removed!']);\n            Plotly.purge(gd);\n            observer.disconnect();\n        }}\n}});\n\n// Listen for the removal of the full notebook cells\nvar notebookContainer = gd.closest('#notebook-container');\nif (notebookContainer) {{\n    x.observe(notebookContainer, {childList: true});\n}}\n\n// Listen for the clearing of the current output cell\nvar outputEl = gd.closest('.output');\nif (outputEl) {{\n    x.observe(outputEl, {childList: true});\n}}\n\n                        })                };                });            </script>        </div>"},"metadata":{}}]},{"cell_type":"markdown","source":"Trial 3","metadata":{}},{"cell_type":"code","source":"# hyperparameter tuning using optuna\n# reference: https://www.kaggle.com/code/hamzaghanmi/xgboost-catboost-using-optuna/notebook?scriptVersionId=94510532\ndef objective(trial,data=X_scaled,target=y):\n    \n    train_x, test_x, train_y, test_y = train_test_split(data, target, test_size=0.33,random_state=1)\n    \n    param = {\n        'tree_method':'gpu_hist', \n        'lambda': trial.suggest_float(\"lambda\", 1e-5, 10.0, log=True),\n        'alpha': trial.suggest_float(\"alpha\", 1e-5, 10.0, log=True),\n        'colsample_bytree': trial.suggest_categorical('colsample_bytree', [0.3,0.4,0.5,0.6,0.7,0.8,0.9,1.0]),\n        'subsample': trial.suggest_categorical('subsample', [0.4,0.5,0.6,0.7,0.8,1.0]),\n        'learning_rate': trial.suggest_categorical('learning_rate', [0.008,0.01,0.012,0.014,0.016,0.018, 0.02]),\n        'n_estimators': 200,\n        'max_depth': trial.suggest_categorical('max_depth', [5,7,9,11,13,15,17]),\n            }\n    model = xgb.XGBClassifier(**param)  \n    \n    model.fit(train_x,train_y,eval_set=[(test_x,test_y)],early_stopping_rounds=100,verbose=False)\n    \n    preds = model.predict(test_x)\n    \n    accuracy = sklearn.metrics.accuracy_score(test_y, preds)\n    \n    return accuracy","metadata":{"execution":{"iopub.status.busy":"2022-06-05T19:45:14.530756Z","iopub.execute_input":"2022-06-05T19:45:14.531608Z","iopub.status.idle":"2022-06-05T19:45:14.543383Z","shell.execute_reply.started":"2022-06-05T19:45:14.531569Z","shell.execute_reply":"2022-06-05T19:45:14.542572Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"# run the study\nstudy3 = optuna.create_study(direction='maximize')\nstudy3.optimize(objective, n_trials=40)\nprint('Number of finished trials:', len(study3.trials))\nprint('Best trial:', study3.best_trial.params)\nprint('Best value:', study3.best_trial.value)","metadata":{"execution":{"iopub.status.busy":"2022-06-05T19:45:19.493400Z","iopub.execute_input":"2022-06-05T19:45:19.493753Z","iopub.status.idle":"2022-06-05T20:39:16.233555Z","shell.execute_reply.started":"2022-06-05T19:45:19.493725Z","shell.execute_reply":"2022-06-05T20:39:16.232829Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stderr","text":"\u001b[32m[I 2022-06-05 19:45:19,495]\u001b[0m A new study created in memory with name: no-name-aa3712b1-5fb3-49e7-85a3-ed4e0eea3628\u001b[0m\n/opt/conda/lib/python3.7/site-packages/xgboost/sklearn.py:797: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n  UserWarning,\n\u001b[32m[I 2022-06-05 19:45:46,515]\u001b[0m Trial 0 finished with value: 0.42098484848484846 and parameters: {'lambda': 6.303103387005962e-05, 'alpha': 4.326504599700511, 'colsample_bytree': 0.5, 'subsample': 0.5, 'learning_rate': 0.018, 'max_depth': 17}. Best is trial 0 with value: 0.42098484848484846.\u001b[0m\n/opt/conda/lib/python3.7/site-packages/xgboost/sklearn.py:797: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n  UserWarning,\n\u001b[32m[I 2022-06-05 19:46:54,097]\u001b[0m Trial 1 finished with value: 0.5328030303030303 and parameters: {'lambda': 0.00022104467592701645, 'alpha': 0.08399351607397701, 'colsample_bytree': 0.4, 'subsample': 0.5, 'learning_rate': 0.018, 'max_depth': 17}. Best is trial 1 with value: 0.5328030303030303.\u001b[0m\n/opt/conda/lib/python3.7/site-packages/xgboost/sklearn.py:797: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n  UserWarning,\n\u001b[32m[I 2022-06-05 19:47:07,542]\u001b[0m Trial 2 finished with value: 0.38143939393939397 and parameters: {'lambda': 0.24668672546287315, 'alpha': 1.6562108332599295e-05, 'colsample_bytree': 0.5, 'subsample': 0.8, 'learning_rate': 0.008, 'max_depth': 5}. Best is trial 1 with value: 0.5328030303030303.\u001b[0m\n/opt/conda/lib/python3.7/site-packages/xgboost/sklearn.py:797: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n  UserWarning,\n\u001b[32m[I 2022-06-05 19:47:33,888]\u001b[0m Trial 3 finished with value: 0.5221969696969697 and parameters: {'lambda': 0.00019065035743288667, 'alpha': 0.9895125799675523, 'colsample_bytree': 1.0, 'subsample': 0.6, 'learning_rate': 0.014, 'max_depth': 7}. Best is trial 1 with value: 0.5328030303030303.\u001b[0m\n/opt/conda/lib/python3.7/site-packages/xgboost/sklearn.py:797: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n  UserWarning,\n\u001b[32m[I 2022-06-05 19:48:01,402]\u001b[0m Trial 4 finished with value: 0.45431818181818184 and parameters: {'lambda': 4.2851387751596555, 'alpha': 0.039716147988966395, 'colsample_bytree': 0.7, 'subsample': 0.8, 'learning_rate': 0.008, 'max_depth': 7}. Best is trial 1 with value: 0.5328030303030303.\u001b[0m\n/opt/conda/lib/python3.7/site-packages/xgboost/sklearn.py:797: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n  UserWarning,\n\u001b[32m[I 2022-06-05 19:50:16,436]\u001b[0m Trial 5 finished with value: 0.6374242424242424 and parameters: {'lambda': 0.014619374171463275, 'alpha': 2.488977285473631e-05, 'colsample_bytree': 0.9, 'subsample': 1.0, 'learning_rate': 0.014, 'max_depth': 13}. Best is trial 5 with value: 0.6374242424242424.\u001b[0m\n/opt/conda/lib/python3.7/site-packages/xgboost/sklearn.py:797: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n  UserWarning,\n\u001b[32m[I 2022-06-05 19:50:29,792]\u001b[0m Trial 6 finished with value: 0.44083333333333335 and parameters: {'lambda': 0.033256647816849824, 'alpha': 0.0020529419652699915, 'colsample_bytree': 0.9, 'subsample': 1.0, 'learning_rate': 0.018, 'max_depth': 5}. Best is trial 5 with value: 0.6374242424242424.\u001b[0m\n/opt/conda/lib/python3.7/site-packages/xgboost/sklearn.py:797: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n  UserWarning,\n\u001b[32m[I 2022-06-05 19:52:06,669]\u001b[0m Trial 7 finished with value: 0.6309090909090909 and parameters: {'lambda': 0.0009902923511362414, 'alpha': 0.03894177101442038, 'colsample_bytree': 0.9, 'subsample': 0.6, 'learning_rate': 0.02, 'max_depth': 13}. Best is trial 5 with value: 0.6374242424242424.\u001b[0m\n/opt/conda/lib/python3.7/site-packages/xgboost/sklearn.py:797: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n  UserWarning,\n\u001b[32m[I 2022-06-05 19:53:08,292]\u001b[0m Trial 8 finished with value: 0.5772727272727273 and parameters: {'lambda': 0.030711618773699188, 'alpha': 0.5874516194104074, 'colsample_bytree': 0.7, 'subsample': 0.6, 'learning_rate': 0.014, 'max_depth': 11}. Best is trial 5 with value: 0.6374242424242424.\u001b[0m\n/opt/conda/lib/python3.7/site-packages/xgboost/sklearn.py:797: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n  UserWarning,\n\u001b[32m[I 2022-06-05 19:54:02,586]\u001b[0m Trial 9 finished with value: 0.5767424242424243 and parameters: {'lambda': 1.5700407030215348e-05, 'alpha': 0.1624260377744462, 'colsample_bytree': 0.6, 'subsample': 0.8, 'learning_rate': 0.016, 'max_depth': 9}. Best is trial 5 with value: 0.6374242424242424.\u001b[0m\n/opt/conda/lib/python3.7/site-packages/xgboost/sklearn.py:797: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n  UserWarning,\n\u001b[32m[I 2022-06-05 19:54:25,820]\u001b[0m Trial 10 finished with value: 0.3112878787878788 and parameters: {'lambda': 0.0026968882451972468, 'alpha': 1.3431851461316922e-05, 'colsample_bytree': 0.3, 'subsample': 0.7, 'learning_rate': 0.012, 'max_depth': 15}. Best is trial 5 with value: 0.6374242424242424.\u001b[0m\n/opt/conda/lib/python3.7/site-packages/xgboost/sklearn.py:797: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n  UserWarning,\n\u001b[32m[I 2022-06-05 19:55:44,592]\u001b[0m Trial 11 finished with value: 0.613030303030303 and parameters: {'lambda': 0.0022903605984782587, 'alpha': 0.0013763153034728247, 'colsample_bytree': 0.9, 'subsample': 0.4, 'learning_rate': 0.02, 'max_depth': 13}. Best is trial 5 with value: 0.6374242424242424.\u001b[0m\n/opt/conda/lib/python3.7/site-packages/xgboost/sklearn.py:797: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n  UserWarning,\n\u001b[32m[I 2022-06-05 19:57:50,239]\u001b[0m Trial 12 finished with value: 0.6438636363636364 and parameters: {'lambda': 0.003191593860397958, 'alpha': 0.00028410188674392876, 'colsample_bytree': 0.9, 'subsample': 1.0, 'learning_rate': 0.02, 'max_depth': 13}. Best is trial 12 with value: 0.6438636363636364.\u001b[0m\n/opt/conda/lib/python3.7/site-packages/xgboost/sklearn.py:797: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n  UserWarning,\n\u001b[32m[I 2022-06-05 20:00:07,362]\u001b[0m Trial 13 finished with value: 0.6278030303030303 and parameters: {'lambda': 0.20680355044537485, 'alpha': 0.00014601192497269908, 'colsample_bytree': 0.8, 'subsample': 1.0, 'learning_rate': 0.01, 'max_depth': 13}. Best is trial 12 with value: 0.6438636363636364.\u001b[0m\n/opt/conda/lib/python3.7/site-packages/xgboost/sklearn.py:797: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n  UserWarning,\n\u001b[32m[I 2022-06-05 20:02:12,838]\u001b[0m Trial 14 finished with value: 0.6418181818181818 and parameters: {'lambda': 0.010701393748153477, 'alpha': 0.00018894728630977276, 'colsample_bytree': 0.9, 'subsample': 1.0, 'learning_rate': 0.02, 'max_depth': 13}. Best is trial 12 with value: 0.6438636363636364.\u001b[0m\n/opt/conda/lib/python3.7/site-packages/xgboost/sklearn.py:797: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n  UserWarning,\n\u001b[32m[I 2022-06-05 20:04:11,732]\u001b[0m Trial 15 finished with value: 0.6356818181818182 and parameters: {'lambda': 0.8641230204941467, 'alpha': 0.0002768085013216396, 'colsample_bytree': 0.9, 'subsample': 1.0, 'learning_rate': 0.02, 'max_depth': 13}. Best is trial 12 with value: 0.6438636363636364.\u001b[0m\n/opt/conda/lib/python3.7/site-packages/xgboost/sklearn.py:797: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n  UserWarning,\n\u001b[32m[I 2022-06-05 20:04:35,710]\u001b[0m Trial 16 finished with value: 0.32886363636363636 and parameters: {'lambda': 0.00535733566681205, 'alpha': 0.0022127632742824283, 'colsample_bytree': 0.3, 'subsample': 1.0, 'learning_rate': 0.02, 'max_depth': 15}. Best is trial 12 with value: 0.6438636363636364.\u001b[0m\n/opt/conda/lib/python3.7/site-packages/xgboost/sklearn.py:797: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n  UserWarning,\n\u001b[32m[I 2022-06-05 20:05:24,229]\u001b[0m Trial 17 finished with value: 0.5203787878787879 and parameters: {'lambda': 0.0005565823250185078, 'alpha': 0.0005567854838528763, 'colsample_bytree': 0.4, 'subsample': 0.4, 'learning_rate': 0.02, 'max_depth': 11}. Best is trial 12 with value: 0.6438636363636364.\u001b[0m\n/opt/conda/lib/python3.7/site-packages/xgboost/sklearn.py:797: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n  UserWarning,\n\u001b[32m[I 2022-06-05 20:06:20,439]\u001b[0m Trial 18 finished with value: 0.5747727272727273 and parameters: {'lambda': 0.07211106864644704, 'alpha': 9.625745275472786e-05, 'colsample_bytree': 0.6, 'subsample': 0.7, 'learning_rate': 0.016, 'max_depth': 9}. Best is trial 12 with value: 0.6438636363636364.\u001b[0m\n/opt/conda/lib/python3.7/site-packages/xgboost/sklearn.py:797: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n  UserWarning,\n\u001b[32m[I 2022-06-05 20:08:40,080]\u001b[0m Trial 19 finished with value: 0.6304545454545455 and parameters: {'lambda': 0.007735339660370653, 'alpha': 0.011580326365258268, 'colsample_bytree': 0.8, 'subsample': 1.0, 'learning_rate': 0.01, 'max_depth': 13}. Best is trial 12 with value: 0.6438636363636364.\u001b[0m\n/opt/conda/lib/python3.7/site-packages/xgboost/sklearn.py:797: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n  UserWarning,\n\u001b[32m[I 2022-06-05 20:10:34,062]\u001b[0m Trial 20 finished with value: 0.5884090909090909 and parameters: {'lambda': 3.2923024288606832, 'alpha': 6.809541286484415e-05, 'colsample_bytree': 1.0, 'subsample': 1.0, 'learning_rate': 0.012, 'max_depth': 13}. Best is trial 12 with value: 0.6438636363636364.\u001b[0m\n/opt/conda/lib/python3.7/site-packages/xgboost/sklearn.py:797: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n  UserWarning,\n\u001b[32m[I 2022-06-05 20:12:49,688]\u001b[0m Trial 21 finished with value: 0.6378030303030303 and parameters: {'lambda': 0.014395879383956816, 'alpha': 3.782267699949838e-05, 'colsample_bytree': 0.9, 'subsample': 1.0, 'learning_rate': 0.014, 'max_depth': 13}. Best is trial 12 with value: 0.6438636363636364.\u001b[0m\n/opt/conda/lib/python3.7/site-packages/xgboost/sklearn.py:797: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n  UserWarning,\n\u001b[32m[I 2022-06-05 20:15:02,802]\u001b[0m Trial 22 finished with value: 0.6370454545454546 and parameters: {'lambda': 0.09989997743191115, 'alpha': 0.0005783388456055521, 'colsample_bytree': 0.9, 'subsample': 1.0, 'learning_rate': 0.014, 'max_depth': 13}. Best is trial 12 with value: 0.6438636363636364.\u001b[0m\n/opt/conda/lib/python3.7/site-packages/xgboost/sklearn.py:797: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n  UserWarning,\n\u001b[32m[I 2022-06-05 20:17:06,821]\u001b[0m Trial 23 finished with value: 0.6439393939393939 and parameters: {'lambda': 0.015488424655677365, 'alpha': 5.91200269888891e-05, 'colsample_bytree': 0.9, 'subsample': 1.0, 'learning_rate': 0.02, 'max_depth': 13}. Best is trial 23 with value: 0.6439393939393939.\u001b[0m\n/opt/conda/lib/python3.7/site-packages/xgboost/sklearn.py:797: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n  UserWarning,\n\u001b[32m[I 2022-06-05 20:19:11,467]\u001b[0m Trial 24 finished with value: 0.6425757575757576 and parameters: {'lambda': 0.001210765396815314, 'alpha': 0.007941121395765204, 'colsample_bytree': 0.9, 'subsample': 1.0, 'learning_rate': 0.02, 'max_depth': 13}. Best is trial 23 with value: 0.6439393939393939.\u001b[0m\n/opt/conda/lib/python3.7/site-packages/xgboost/sklearn.py:797: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n  UserWarning,\n\u001b[32m[I 2022-06-05 20:21:16,028]\u001b[0m Trial 25 finished with value: 0.6428787878787878 and parameters: {'lambda': 0.0010608865697233853, 'alpha': 0.007280163728392596, 'colsample_bytree': 0.9, 'subsample': 1.0, 'learning_rate': 0.02, 'max_depth': 13}. Best is trial 23 with value: 0.6439393939393939.\u001b[0m\n/opt/conda/lib/python3.7/site-packages/xgboost/sklearn.py:797: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n  UserWarning,\n\u001b[32m[I 2022-06-05 20:21:42,557]\u001b[0m Trial 26 finished with value: 0.536060606060606 and parameters: {'lambda': 0.00035572024287927167, 'alpha': 0.005330347606596222, 'colsample_bytree': 0.9, 'subsample': 0.4, 'learning_rate': 0.02, 'max_depth': 7}. Best is trial 23 with value: 0.6439393939393939.\u001b[0m\n/opt/conda/lib/python3.7/site-packages/xgboost/sklearn.py:797: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n  UserWarning,\n\u001b[32m[I 2022-06-05 20:23:40,733]\u001b[0m Trial 27 finished with value: 0.6288636363636364 and parameters: {'lambda': 0.0028499417022020772, 'alpha': 0.0006427272038025059, 'colsample_bytree': 0.9, 'subsample': 0.5, 'learning_rate': 0.02, 'max_depth': 17}. Best is trial 23 with value: 0.6439393939393939.\u001b[0m\n/opt/conda/lib/python3.7/site-packages/xgboost/sklearn.py:797: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n  UserWarning,\n\u001b[32m[I 2022-06-05 20:23:54,614]\u001b[0m Trial 28 finished with value: 0.45045454545454544 and parameters: {'lambda': 7.462482291810685e-05, 'alpha': 5.3378952999907345e-05, 'colsample_bytree': 0.7, 'subsample': 0.7, 'learning_rate': 0.02, 'max_depth': 5}. Best is trial 23 with value: 0.6439393939393939.\u001b[0m\n/opt/conda/lib/python3.7/site-packages/xgboost/sklearn.py:797: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n  UserWarning,\n\u001b[32m[I 2022-06-05 20:24:14,746]\u001b[0m Trial 29 finished with value: 0.4471969696969697 and parameters: {'lambda': 1.0422716514645213e-05, 'alpha': 5.611061454078792, 'colsample_bytree': 0.5, 'subsample': 1.0, 'learning_rate': 0.02, 'max_depth': 9}. Best is trial 23 with value: 0.6439393939393939.\u001b[0m\n/opt/conda/lib/python3.7/site-packages/xgboost/sklearn.py:797: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n  UserWarning,\n\u001b[32m[I 2022-06-05 20:25:56,638]\u001b[0m Trial 30 finished with value: 0.6046969696969697 and parameters: {'lambda': 0.0009581798709199054, 'alpha': 1.0167789805105636e-05, 'colsample_bytree': 0.6, 'subsample': 0.5, 'learning_rate': 0.016, 'max_depth': 15}. Best is trial 23 with value: 0.6439393939393939.\u001b[0m\n/opt/conda/lib/python3.7/site-packages/xgboost/sklearn.py:797: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n  UserWarning,\n\u001b[32m[I 2022-06-05 20:28:00,963]\u001b[0m Trial 31 finished with value: 0.6427272727272727 and parameters: {'lambda': 0.0011895665824672708, 'alpha': 0.009872855872708027, 'colsample_bytree': 0.9, 'subsample': 1.0, 'learning_rate': 0.02, 'max_depth': 13}. Best is trial 23 with value: 0.6439393939393939.\u001b[0m\n/opt/conda/lib/python3.7/site-packages/xgboost/sklearn.py:797: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n  UserWarning,\n\u001b[32m[I 2022-06-05 20:29:36,928]\u001b[0m Trial 32 finished with value: 0.5575 and parameters: {'lambda': 0.00010075265151424202, 'alpha': 0.015597660802925498, 'colsample_bytree': 0.4, 'subsample': 1.0, 'learning_rate': 0.018, 'max_depth': 17}. Best is trial 23 with value: 0.6439393939393939.\u001b[0m\n/opt/conda/lib/python3.7/site-packages/xgboost/sklearn.py:797: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n  UserWarning,\n\u001b[32m[I 2022-06-05 20:31:41,439]\u001b[0m Trial 33 finished with value: 0.6420454545454546 and parameters: {'lambda': 0.004865155727565805, 'alpha': 0.004153609334110903, 'colsample_bytree': 0.9, 'subsample': 1.0, 'learning_rate': 0.02, 'max_depth': 13}. Best is trial 23 with value: 0.6439393939393939.\u001b[0m\n/opt/conda/lib/python3.7/site-packages/xgboost/sklearn.py:797: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n  UserWarning,\n\u001b[32m[I 2022-06-05 20:32:45,799]\u001b[0m Trial 34 finished with value: 0.516969696969697 and parameters: {'lambda': 0.00023738078296664533, 'alpha': 0.24895602571933764, 'colsample_bytree': 0.5, 'subsample': 1.0, 'learning_rate': 0.008, 'max_depth': 13}. Best is trial 23 with value: 0.6439393939393939.\u001b[0m\n/opt/conda/lib/python3.7/site-packages/xgboost/sklearn.py:797: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n  UserWarning,\n\u001b[32m[I 2022-06-05 20:34:06,003]\u001b[0m Trial 35 finished with value: 0.6343939393939394 and parameters: {'lambda': 0.02905985569401296, 'alpha': 0.022462184341078602, 'colsample_bytree': 1.0, 'subsample': 0.8, 'learning_rate': 0.02, 'max_depth': 11}. Best is trial 23 with value: 0.6439393939393939.\u001b[0m\n/opt/conda/lib/python3.7/site-packages/xgboost/sklearn.py:797: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n  UserWarning,\n\u001b[32m[I 2022-06-05 20:35:36,162]\u001b[0m Trial 36 finished with value: 0.6074242424242424 and parameters: {'lambda': 0.0005573744361611045, 'alpha': 0.09601249340913773, 'colsample_bytree': 0.9, 'subsample': 0.5, 'learning_rate': 0.012, 'max_depth': 13}. Best is trial 23 with value: 0.6439393939393939.\u001b[0m\n/opt/conda/lib/python3.7/site-packages/xgboost/sklearn.py:797: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n  UserWarning,\n\u001b[32m[I 2022-06-05 20:36:01,097]\u001b[0m Trial 37 finished with value: 0.4840151515151515 and parameters: {'lambda': 0.0017092860456782565, 'alpha': 1.8970896377052437, 'colsample_bytree': 0.9, 'subsample': 0.6, 'learning_rate': 0.008, 'max_depth': 7}. Best is trial 23 with value: 0.6439393939393939.\u001b[0m\n/opt/conda/lib/python3.7/site-packages/xgboost/sklearn.py:797: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n  UserWarning,\n\u001b[32m[I 2022-06-05 20:36:11,389]\u001b[0m Trial 38 finished with value: 0.30863636363636365 and parameters: {'lambda': 0.00016903831331242675, 'alpha': 0.0013468031994570211, 'colsample_bytree': 0.3, 'subsample': 1.0, 'learning_rate': 0.018, 'max_depth': 5}. Best is trial 23 with value: 0.6439393939393939.\u001b[0m\n/opt/conda/lib/python3.7/site-packages/xgboost/sklearn.py:797: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n  UserWarning,\n\u001b[32m[I 2022-06-05 20:39:16,220]\u001b[0m Trial 39 finished with value: 0.638560606060606 and parameters: {'lambda': 2.625690809512848e-05, 'alpha': 0.04536553379235141, 'colsample_bytree': 0.8, 'subsample': 1.0, 'learning_rate': 0.01, 'max_depth': 17}. Best is trial 23 with value: 0.6439393939393939.\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"Number of finished trials: 40\nBest trial: {'lambda': 0.015488424655677365, 'alpha': 5.91200269888891e-05, 'colsample_bytree': 0.9, 'subsample': 1.0, 'learning_rate': 0.02, 'max_depth': 13}\nBest value: 0.6439393939393939\n","output_type":"stream"}]},{"cell_type":"code","source":"#record trail history\nprint('Best trial:', study3.best_trial.params)\nhist = study3.trials_dataframe()\nhist.head()","metadata":{"execution":{"iopub.status.busy":"2022-06-05T20:53:16.744479Z","iopub.execute_input":"2022-06-05T20:53:16.745060Z","iopub.status.idle":"2022-06-05T20:53:16.783461Z","shell.execute_reply.started":"2022-06-05T20:53:16.745017Z","shell.execute_reply":"2022-06-05T20:53:16.782742Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"Best trial: {'lambda': 0.015488424655677365, 'alpha': 5.91200269888891e-05, 'colsample_bytree': 0.9, 'subsample': 1.0, 'learning_rate': 0.02, 'max_depth': 13}\n","output_type":"stream"},{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"   number     value             datetime_start          datetime_complete  \\\n0       0  0.420985 2022-06-05 19:45:19.499553 2022-06-05 19:45:46.514813   \n1       1  0.532803 2022-06-05 19:45:46.516795 2022-06-05 19:46:54.096820   \n2       2  0.381439 2022-06-05 19:46:54.098666 2022-06-05 19:47:07.541923   \n3       3  0.522197 2022-06-05 19:47:07.543953 2022-06-05 19:47:33.888255   \n4       4  0.454318 2022-06-05 19:47:33.892285 2022-06-05 19:48:01.402033   \n\n                duration  params_alpha  params_colsample_bytree  \\\n0 0 days 00:00:27.015260      4.326505                      0.5   \n1 0 days 00:01:07.580025      0.083994                      0.4   \n2 0 days 00:00:13.443257      0.000017                      0.5   \n3 0 days 00:00:26.344302      0.989513                      1.0   \n4 0 days 00:00:27.509748      0.039716                      0.7   \n\n   params_lambda  params_learning_rate  params_max_depth  params_subsample  \\\n0       0.000063                 0.018                17               0.5   \n1       0.000221                 0.018                17               0.5   \n2       0.246687                 0.008                 5               0.8   \n3       0.000191                 0.014                 7               0.6   \n4       4.285139                 0.008                 7               0.8   \n\n      state  \n0  COMPLETE  \n1  COMPLETE  \n2  COMPLETE  \n3  COMPLETE  \n4  COMPLETE  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>number</th>\n      <th>value</th>\n      <th>datetime_start</th>\n      <th>datetime_complete</th>\n      <th>duration</th>\n      <th>params_alpha</th>\n      <th>params_colsample_bytree</th>\n      <th>params_lambda</th>\n      <th>params_learning_rate</th>\n      <th>params_max_depth</th>\n      <th>params_subsample</th>\n      <th>state</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0.420985</td>\n      <td>2022-06-05 19:45:19.499553</td>\n      <td>2022-06-05 19:45:46.514813</td>\n      <td>0 days 00:00:27.015260</td>\n      <td>4.326505</td>\n      <td>0.5</td>\n      <td>0.000063</td>\n      <td>0.018</td>\n      <td>17</td>\n      <td>0.5</td>\n      <td>COMPLETE</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>0.532803</td>\n      <td>2022-06-05 19:45:46.516795</td>\n      <td>2022-06-05 19:46:54.096820</td>\n      <td>0 days 00:01:07.580025</td>\n      <td>0.083994</td>\n      <td>0.4</td>\n      <td>0.000221</td>\n      <td>0.018</td>\n      <td>17</td>\n      <td>0.5</td>\n      <td>COMPLETE</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>0.381439</td>\n      <td>2022-06-05 19:46:54.098666</td>\n      <td>2022-06-05 19:47:07.541923</td>\n      <td>0 days 00:00:13.443257</td>\n      <td>0.000017</td>\n      <td>0.5</td>\n      <td>0.246687</td>\n      <td>0.008</td>\n      <td>5</td>\n      <td>0.8</td>\n      <td>COMPLETE</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>0.522197</td>\n      <td>2022-06-05 19:47:07.543953</td>\n      <td>2022-06-05 19:47:33.888255</td>\n      <td>0 days 00:00:26.344302</td>\n      <td>0.989513</td>\n      <td>1.0</td>\n      <td>0.000191</td>\n      <td>0.014</td>\n      <td>7</td>\n      <td>0.6</td>\n      <td>COMPLETE</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>0.454318</td>\n      <td>2022-06-05 19:47:33.892285</td>\n      <td>2022-06-05 19:48:01.402033</td>\n      <td>0 days 00:00:27.509748</td>\n      <td>0.039716</td>\n      <td>0.7</td>\n      <td>4.285139</td>\n      <td>0.008</td>\n      <td>7</td>\n      <td>0.8</td>\n      <td>COMPLETE</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# Plot optimization histroy of all trials as well as the best score\noptuna.visualization.plot_optimization_history(study3)","metadata":{"execution":{"iopub.status.busy":"2022-06-05T20:54:27.957548Z","iopub.execute_input":"2022-06-05T20:54:27.957928Z","iopub.status.idle":"2022-06-05T20:54:28.072891Z","shell.execute_reply.started":"2022-06-05T20:54:27.957894Z","shell.execute_reply":"2022-06-05T20:54:28.072204Z"},"trusted":true},"execution_count":13,"outputs":[{"output_type":"display_data","data":{"text/html":"        <script type=\"text/javascript\">\n        window.PlotlyConfig = {MathJaxConfig: 'local'};\n        if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n        if (typeof require !== 'undefined') {\n        require.undef(\"plotly\");\n        requirejs.config({\n            paths: {\n                'plotly': ['https://cdn.plot.ly/plotly-2.12.1.min']\n            }\n        });\n        require(['plotly'], function(Plotly) {\n            window._Plotly = Plotly;\n        });\n        }\n        </script>\n        "},"metadata":{}},{"output_type":"display_data","data":{"text/html":"<div>                            <div id=\"d9d76b9a-3153-4061-a6e5-0a06d426f08c\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"d9d76b9a-3153-4061-a6e5-0a06d426f08c\")) {                    Plotly.newPlot(                        \"d9d76b9a-3153-4061-a6e5-0a06d426f08c\",                        [{\"mode\":\"markers\",\"name\":\"Objective Value\",\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39],\"y\":[0.42098484848484846,0.5328030303030303,0.38143939393939397,0.5221969696969697,0.45431818181818184,0.6374242424242424,0.44083333333333335,0.6309090909090909,0.5772727272727273,0.5767424242424243,0.3112878787878788,0.613030303030303,0.6438636363636364,0.6278030303030303,0.6418181818181818,0.6356818181818182,0.32886363636363636,0.5203787878787879,0.5747727272727273,0.6304545454545455,0.5884090909090909,0.6378030303030303,0.6370454545454546,0.6439393939393939,0.6425757575757576,0.6428787878787878,0.536060606060606,0.6288636363636364,0.45045454545454544,0.4471969696969697,0.6046969696969697,0.6427272727272727,0.5575,0.6420454545454546,0.516969696969697,0.6343939393939394,0.6074242424242424,0.4840151515151515,0.30863636363636365,0.638560606060606],\"type\":\"scatter\"},{\"name\":\"Best Value\",\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39],\"y\":[0.42098484848484846,0.5328030303030303,0.5328030303030303,0.5328030303030303,0.5328030303030303,0.6374242424242424,0.6374242424242424,0.6374242424242424,0.6374242424242424,0.6374242424242424,0.6374242424242424,0.6374242424242424,0.6438636363636364,0.6438636363636364,0.6438636363636364,0.6438636363636364,0.6438636363636364,0.6438636363636364,0.6438636363636364,0.6438636363636364,0.6438636363636364,0.6438636363636364,0.6438636363636364,0.6439393939393939,0.6439393939393939,0.6439393939393939,0.6439393939393939,0.6439393939393939,0.6439393939393939,0.6439393939393939,0.6439393939393939,0.6439393939393939,0.6439393939393939,0.6439393939393939,0.6439393939393939,0.6439393939393939,0.6439393939393939,0.6439393939393939,0.6439393939393939,0.6439393939393939],\"type\":\"scatter\"}],                        {\"title\":{\"text\":\"Optimization History Plot\"},\"xaxis\":{\"title\":{\"text\":\"#Trials\"}},\"yaxis\":{\"title\":{\"text\":\"Objective Value\"}},\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}}},                        {\"responsive\": true}                    ).then(function(){\n                            \nvar gd = document.getElementById('d9d76b9a-3153-4061-a6e5-0a06d426f08c');\nvar x = new MutationObserver(function (mutations, observer) {{\n        var display = window.getComputedStyle(gd).display;\n        if (!display || display === 'none') {{\n            console.log([gd, 'removed!']);\n            Plotly.purge(gd);\n            observer.disconnect();\n        }}\n}});\n\n// Listen for the removal of the full notebook cells\nvar notebookContainer = gd.closest('#notebook-container');\nif (notebookContainer) {{\n    x.observe(notebookContainer, {childList: true});\n}}\n\n// Listen for the clearing of the current output cell\nvar outputEl = gd.closest('.output');\nif (outputEl) {{\n    x.observe(outputEl, {childList: true});\n}}\n\n                        })                };                });            </script>        </div>"},"metadata":{}}]},{"cell_type":"code","source":"#plot the parameter relationshiip as slice\noptuna.visualization.plot_slice(study3)","metadata":{"execution":{"iopub.status.busy":"2022-06-05T21:11:42.365220Z","iopub.execute_input":"2022-06-05T21:11:42.365602Z","iopub.status.idle":"2022-06-05T21:11:42.621594Z","shell.execute_reply.started":"2022-06-05T21:11:42.365570Z","shell.execute_reply":"2022-06-05T21:11:42.620589Z"},"trusted":true},"execution_count":14,"outputs":[{"output_type":"display_data","data":{"text/html":"<div>                            <div id=\"7d6bd970-dff5-414c-9735-d52516f68003\" class=\"plotly-graph-div\" style=\"height:525px; width:1800px;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"7d6bd970-dff5-414c-9735-d52516f68003\")) {                    Plotly.newPlot(                        \"7d6bd970-dff5-414c-9735-d52516f68003\",                        [{\"marker\":{\"color\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39],\"colorbar\":{\"title\":{\"text\":\"#Trials\"},\"x\":1.0,\"xpad\":40},\"colorscale\":[[0.0,\"rgb(247,251,255)\"],[0.125,\"rgb(222,235,247)\"],[0.25,\"rgb(198,219,239)\"],[0.375,\"rgb(158,202,225)\"],[0.5,\"rgb(107,174,214)\"],[0.625,\"rgb(66,146,198)\"],[0.75,\"rgb(33,113,181)\"],[0.875,\"rgb(8,81,156)\"],[1.0,\"rgb(8,48,107)\"]],\"line\":{\"color\":\"Grey\",\"width\":0.5},\"showscale\":true},\"mode\":\"markers\",\"showlegend\":false,\"x\":[4.326504599700511,0.08399351607397701,0.000016562108332599295,0.9895125799675523,0.039716147988966395,0.00002488977285473631,0.0020529419652699915,0.03894177101442038,0.5874516194104074,0.1624260377744462,0.000013431851461316922,0.0013763153034728247,0.00028410188674392876,0.00014601192497269908,0.00018894728630977276,0.0002768085013216396,0.0022127632742824283,0.0005567854838528763,0.00009625745275472786,0.011580326365258268,0.00006809541286484415,0.00003782267699949838,0.0005783388456055521,0.0000591200269888891,0.007941121395765204,0.007280163728392596,0.005330347606596222,0.0006427272038025059,0.000053378952999907345,5.611061454078792,0.000010167789805105636,0.009872855872708027,0.015597660802925498,0.004153609334110903,0.24895602571933764,0.022462184341078602,0.09601249340913773,1.8970896377052437,0.0013468031994570211,0.04536553379235141],\"y\":[0.42098484848484846,0.5328030303030303,0.38143939393939397,0.5221969696969697,0.45431818181818184,0.6374242424242424,0.44083333333333335,0.6309090909090909,0.5772727272727273,0.5767424242424243,0.3112878787878788,0.613030303030303,0.6438636363636364,0.6278030303030303,0.6418181818181818,0.6356818181818182,0.32886363636363636,0.5203787878787879,0.5747727272727273,0.6304545454545455,0.5884090909090909,0.6378030303030303,0.6370454545454546,0.6439393939393939,0.6425757575757576,0.6428787878787878,0.536060606060606,0.6288636363636364,0.45045454545454544,0.4471969696969697,0.6046969696969697,0.6427272727272727,0.5575,0.6420454545454546,0.516969696969697,0.6343939393939394,0.6074242424242424,0.4840151515151515,0.30863636363636365,0.638560606060606],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"marker\":{\"color\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39],\"colorbar\":{\"title\":{\"text\":\"#Trials\"},\"x\":1.0,\"xpad\":40},\"colorscale\":[[0.0,\"rgb(247,251,255)\"],[0.125,\"rgb(222,235,247)\"],[0.25,\"rgb(198,219,239)\"],[0.375,\"rgb(158,202,225)\"],[0.5,\"rgb(107,174,214)\"],[0.625,\"rgb(66,146,198)\"],[0.75,\"rgb(33,113,181)\"],[0.875,\"rgb(8,81,156)\"],[1.0,\"rgb(8,48,107)\"]],\"line\":{\"color\":\"Grey\",\"width\":0.5},\"showscale\":false},\"mode\":\"markers\",\"showlegend\":false,\"x\":[0.5,0.4,0.5,1.0,0.7,0.9,0.9,0.9,0.7,0.6,0.3,0.9,0.9,0.8,0.9,0.9,0.3,0.4,0.6,0.8,1.0,0.9,0.9,0.9,0.9,0.9,0.9,0.9,0.7,0.5,0.6,0.9,0.4,0.9,0.5,1.0,0.9,0.9,0.3,0.8],\"y\":[0.42098484848484846,0.5328030303030303,0.38143939393939397,0.5221969696969697,0.45431818181818184,0.6374242424242424,0.44083333333333335,0.6309090909090909,0.5772727272727273,0.5767424242424243,0.3112878787878788,0.613030303030303,0.6438636363636364,0.6278030303030303,0.6418181818181818,0.6356818181818182,0.32886363636363636,0.5203787878787879,0.5747727272727273,0.6304545454545455,0.5884090909090909,0.6378030303030303,0.6370454545454546,0.6439393939393939,0.6425757575757576,0.6428787878787878,0.536060606060606,0.6288636363636364,0.45045454545454544,0.4471969696969697,0.6046969696969697,0.6427272727272727,0.5575,0.6420454545454546,0.516969696969697,0.6343939393939394,0.6074242424242424,0.4840151515151515,0.30863636363636365,0.638560606060606],\"type\":\"scatter\",\"xaxis\":\"x2\",\"yaxis\":\"y2\"},{\"marker\":{\"color\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39],\"colorbar\":{\"title\":{\"text\":\"#Trials\"},\"x\":1.0,\"xpad\":40},\"colorscale\":[[0.0,\"rgb(247,251,255)\"],[0.125,\"rgb(222,235,247)\"],[0.25,\"rgb(198,219,239)\"],[0.375,\"rgb(158,202,225)\"],[0.5,\"rgb(107,174,214)\"],[0.625,\"rgb(66,146,198)\"],[0.75,\"rgb(33,113,181)\"],[0.875,\"rgb(8,81,156)\"],[1.0,\"rgb(8,48,107)\"]],\"line\":{\"color\":\"Grey\",\"width\":0.5},\"showscale\":false},\"mode\":\"markers\",\"showlegend\":false,\"x\":[0.00006303103387005962,0.00022104467592701645,0.24668672546287315,0.00019065035743288667,4.2851387751596555,0.014619374171463275,0.033256647816849824,0.0009902923511362414,0.030711618773699188,0.000015700407030215348,0.0026968882451972468,0.0022903605984782587,0.003191593860397958,0.20680355044537485,0.010701393748153477,0.8641230204941467,0.00535733566681205,0.0005565823250185078,0.07211106864644704,0.007735339660370653,3.2923024288606832,0.014395879383956816,0.09989997743191115,0.015488424655677365,0.001210765396815314,0.0010608865697233853,0.00035572024287927167,0.0028499417022020772,0.00007462482291810685,0.000010422716514645213,0.0009581798709199054,0.0011895665824672708,0.00010075265151424202,0.004865155727565805,0.00023738078296664533,0.02905985569401296,0.0005573744361611045,0.0017092860456782565,0.00016903831331242675,0.00002625690809512848],\"y\":[0.42098484848484846,0.5328030303030303,0.38143939393939397,0.5221969696969697,0.45431818181818184,0.6374242424242424,0.44083333333333335,0.6309090909090909,0.5772727272727273,0.5767424242424243,0.3112878787878788,0.613030303030303,0.6438636363636364,0.6278030303030303,0.6418181818181818,0.6356818181818182,0.32886363636363636,0.5203787878787879,0.5747727272727273,0.6304545454545455,0.5884090909090909,0.6378030303030303,0.6370454545454546,0.6439393939393939,0.6425757575757576,0.6428787878787878,0.536060606060606,0.6288636363636364,0.45045454545454544,0.4471969696969697,0.6046969696969697,0.6427272727272727,0.5575,0.6420454545454546,0.516969696969697,0.6343939393939394,0.6074242424242424,0.4840151515151515,0.30863636363636365,0.638560606060606],\"type\":\"scatter\",\"xaxis\":\"x3\",\"yaxis\":\"y3\"},{\"marker\":{\"color\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39],\"colorbar\":{\"title\":{\"text\":\"#Trials\"},\"x\":1.0,\"xpad\":40},\"colorscale\":[[0.0,\"rgb(247,251,255)\"],[0.125,\"rgb(222,235,247)\"],[0.25,\"rgb(198,219,239)\"],[0.375,\"rgb(158,202,225)\"],[0.5,\"rgb(107,174,214)\"],[0.625,\"rgb(66,146,198)\"],[0.75,\"rgb(33,113,181)\"],[0.875,\"rgb(8,81,156)\"],[1.0,\"rgb(8,48,107)\"]],\"line\":{\"color\":\"Grey\",\"width\":0.5},\"showscale\":false},\"mode\":\"markers\",\"showlegend\":false,\"x\":[0.018,0.018,0.008,0.014,0.008,0.014,0.018,0.02,0.014,0.016,0.012,0.02,0.02,0.01,0.02,0.02,0.02,0.02,0.016,0.01,0.012,0.014,0.014,0.02,0.02,0.02,0.02,0.02,0.02,0.02,0.016,0.02,0.018,0.02,0.008,0.02,0.012,0.008,0.018,0.01],\"y\":[0.42098484848484846,0.5328030303030303,0.38143939393939397,0.5221969696969697,0.45431818181818184,0.6374242424242424,0.44083333333333335,0.6309090909090909,0.5772727272727273,0.5767424242424243,0.3112878787878788,0.613030303030303,0.6438636363636364,0.6278030303030303,0.6418181818181818,0.6356818181818182,0.32886363636363636,0.5203787878787879,0.5747727272727273,0.6304545454545455,0.5884090909090909,0.6378030303030303,0.6370454545454546,0.6439393939393939,0.6425757575757576,0.6428787878787878,0.536060606060606,0.6288636363636364,0.45045454545454544,0.4471969696969697,0.6046969696969697,0.6427272727272727,0.5575,0.6420454545454546,0.516969696969697,0.6343939393939394,0.6074242424242424,0.4840151515151515,0.30863636363636365,0.638560606060606],\"type\":\"scatter\",\"xaxis\":\"x4\",\"yaxis\":\"y4\"},{\"marker\":{\"color\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39],\"colorbar\":{\"title\":{\"text\":\"#Trials\"},\"x\":1.0,\"xpad\":40},\"colorscale\":[[0.0,\"rgb(247,251,255)\"],[0.125,\"rgb(222,235,247)\"],[0.25,\"rgb(198,219,239)\"],[0.375,\"rgb(158,202,225)\"],[0.5,\"rgb(107,174,214)\"],[0.625,\"rgb(66,146,198)\"],[0.75,\"rgb(33,113,181)\"],[0.875,\"rgb(8,81,156)\"],[1.0,\"rgb(8,48,107)\"]],\"line\":{\"color\":\"Grey\",\"width\":0.5},\"showscale\":false},\"mode\":\"markers\",\"showlegend\":false,\"x\":[17,17,5,7,7,13,5,13,11,9,15,13,13,13,13,13,15,11,9,13,13,13,13,13,13,13,7,17,5,9,15,13,17,13,13,11,13,7,5,17],\"y\":[0.42098484848484846,0.5328030303030303,0.38143939393939397,0.5221969696969697,0.45431818181818184,0.6374242424242424,0.44083333333333335,0.6309090909090909,0.5772727272727273,0.5767424242424243,0.3112878787878788,0.613030303030303,0.6438636363636364,0.6278030303030303,0.6418181818181818,0.6356818181818182,0.32886363636363636,0.5203787878787879,0.5747727272727273,0.6304545454545455,0.5884090909090909,0.6378030303030303,0.6370454545454546,0.6439393939393939,0.6425757575757576,0.6428787878787878,0.536060606060606,0.6288636363636364,0.45045454545454544,0.4471969696969697,0.6046969696969697,0.6427272727272727,0.5575,0.6420454545454546,0.516969696969697,0.6343939393939394,0.6074242424242424,0.4840151515151515,0.30863636363636365,0.638560606060606],\"type\":\"scatter\",\"xaxis\":\"x5\",\"yaxis\":\"y5\"},{\"marker\":{\"color\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39],\"colorbar\":{\"title\":{\"text\":\"#Trials\"},\"x\":1.0,\"xpad\":40},\"colorscale\":[[0.0,\"rgb(247,251,255)\"],[0.125,\"rgb(222,235,247)\"],[0.25,\"rgb(198,219,239)\"],[0.375,\"rgb(158,202,225)\"],[0.5,\"rgb(107,174,214)\"],[0.625,\"rgb(66,146,198)\"],[0.75,\"rgb(33,113,181)\"],[0.875,\"rgb(8,81,156)\"],[1.0,\"rgb(8,48,107)\"]],\"line\":{\"color\":\"Grey\",\"width\":0.5},\"showscale\":false},\"mode\":\"markers\",\"showlegend\":false,\"x\":[0.5,0.5,0.8,0.6,0.8,1.0,1.0,0.6,0.6,0.8,0.7,0.4,1.0,1.0,1.0,1.0,1.0,0.4,0.7,1.0,1.0,1.0,1.0,1.0,1.0,1.0,0.4,0.5,0.7,1.0,0.5,1.0,1.0,1.0,1.0,0.8,0.5,0.6,1.0,1.0],\"y\":[0.42098484848484846,0.5328030303030303,0.38143939393939397,0.5221969696969697,0.45431818181818184,0.6374242424242424,0.44083333333333335,0.6309090909090909,0.5772727272727273,0.5767424242424243,0.3112878787878788,0.613030303030303,0.6438636363636364,0.6278030303030303,0.6418181818181818,0.6356818181818182,0.32886363636363636,0.5203787878787879,0.5747727272727273,0.6304545454545455,0.5884090909090909,0.6378030303030303,0.6370454545454546,0.6439393939393939,0.6425757575757576,0.6428787878787878,0.536060606060606,0.6288636363636364,0.45045454545454544,0.4471969696969697,0.6046969696969697,0.6427272727272727,0.5575,0.6420454545454546,0.516969696969697,0.6343939393939394,0.6074242424242424,0.4840151515151515,0.30863636363636365,0.638560606060606],\"type\":\"scatter\",\"xaxis\":\"x6\",\"yaxis\":\"y6\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,0.1388888888888889],\"title\":{\"text\":\"alpha\"},\"type\":\"log\"},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Objective Value\"}},\"xaxis2\":{\"anchor\":\"y2\",\"domain\":[0.17222222222222222,0.3111111111111111],\"title\":{\"text\":\"colsample_bytree\"}},\"yaxis2\":{\"anchor\":\"x2\",\"domain\":[0.0,1.0],\"matches\":\"y\",\"showticklabels\":false},\"xaxis3\":{\"anchor\":\"y3\",\"domain\":[0.34444444444444444,0.48333333333333334],\"title\":{\"text\":\"lambda\"},\"type\":\"log\"},\"yaxis3\":{\"anchor\":\"x3\",\"domain\":[0.0,1.0],\"matches\":\"y\",\"showticklabels\":false},\"xaxis4\":{\"anchor\":\"y4\",\"domain\":[0.5166666666666667,0.6555555555555557],\"title\":{\"text\":\"learning_rate\"}},\"yaxis4\":{\"anchor\":\"x4\",\"domain\":[0.0,1.0],\"matches\":\"y\",\"showticklabels\":false},\"xaxis5\":{\"anchor\":\"y5\",\"domain\":[0.6888888888888889,0.8277777777777777],\"title\":{\"text\":\"max_depth\"}},\"yaxis5\":{\"anchor\":\"x5\",\"domain\":[0.0,1.0],\"matches\":\"y\",\"showticklabels\":false},\"xaxis6\":{\"anchor\":\"y6\",\"domain\":[0.861111111111111,1.0],\"title\":{\"text\":\"subsample\"}},\"yaxis6\":{\"anchor\":\"x6\",\"domain\":[0.0,1.0],\"matches\":\"y\",\"showticklabels\":false},\"title\":{\"text\":\"Slice Plot\"},\"width\":1800},                        {\"responsive\": true}                    ).then(function(){\n                            \nvar gd = document.getElementById('7d6bd970-dff5-414c-9735-d52516f68003');\nvar x = new MutationObserver(function (mutations, observer) {{\n        var display = window.getComputedStyle(gd).display;\n        if (!display || display === 'none') {{\n            console.log([gd, 'removed!']);\n            Plotly.purge(gd);\n            observer.disconnect();\n        }}\n}});\n\n// Listen for the removal of the full notebook cells\nvar notebookContainer = gd.closest('#notebook-container');\nif (notebookContainer) {{\n    x.observe(notebookContainer, {childList: true});\n}}\n\n// Listen for the clearing of the current output cell\nvar outputEl = gd.closest('.output');\nif (outputEl) {{\n    x.observe(outputEl, {childList: true});\n}}\n\n                        })                };                });            </script>        </div>"},"metadata":{}}]},{"cell_type":"code","source":"#Visualize parameter importances\noptuna.visualization.plot_param_importances(study3)","metadata":{"execution":{"iopub.status.busy":"2022-06-05T21:13:16.289079Z","iopub.execute_input":"2022-06-05T21:13:16.289966Z","iopub.status.idle":"2022-06-05T21:13:17.541483Z","shell.execute_reply.started":"2022-06-05T21:13:16.289919Z","shell.execute_reply":"2022-06-05T21:13:17.540634Z"},"trusted":true},"execution_count":15,"outputs":[{"output_type":"display_data","data":{"text/html":"<div>                            <div id=\"b3c39c77-71ef-4d0f-8221-abf515c0df69\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"b3c39c77-71ef-4d0f-8221-abf515c0df69\")) {                    Plotly.newPlot(                        \"b3c39c77-71ef-4d0f-8221-abf515c0df69\",                        [{\"cliponaxis\":false,\"hovertemplate\":[\"lambda (LogUniformDistribution): 0.00016291858127093277<extra></extra>\",\"alpha (LogUniformDistribution): 0.009875662919565553<extra></extra>\",\"subsample (CategoricalDistribution): 0.0239246639843655<extra></extra>\",\"learning_rate (CategoricalDistribution): 0.043898451917518205<extra></extra>\",\"max_depth (CategoricalDistribution): 0.29437570191110096<extra></extra>\",\"colsample_bytree (CategoricalDistribution): 0.627762600686179<extra></extra>\"],\"marker\":{\"color\":\"rgb(66,146,198)\"},\"orientation\":\"h\",\"text\":[\"0.00016291858127093277\",\"0.009875662919565553\",\"0.0239246639843655\",\"0.043898451917518205\",\"0.29437570191110096\",\"0.627762600686179\"],\"textposition\":\"outside\",\"texttemplate\":\"%{text:.2f}\",\"x\":[0.00016291858127093277,0.009875662919565553,0.0239246639843655,0.043898451917518205,0.29437570191110096,0.627762600686179],\"y\":[\"lambda\",\"alpha\",\"subsample\",\"learning_rate\",\"max_depth\",\"colsample_bytree\"],\"type\":\"bar\"}],                        {\"showlegend\":false,\"title\":{\"text\":\"Hyperparameter Importances\"},\"xaxis\":{\"title\":{\"text\":\"Importance for Objective Value\"}},\"yaxis\":{\"title\":{\"text\":\"Hyperparameter\"}},\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}}},                        {\"responsive\": true}                    ).then(function(){\n                            \nvar gd = document.getElementById('b3c39c77-71ef-4d0f-8221-abf515c0df69');\nvar x = new MutationObserver(function (mutations, observer) {{\n        var display = window.getComputedStyle(gd).display;\n        if (!display || display === 'none') {{\n            console.log([gd, 'removed!']);\n            Plotly.purge(gd);\n            observer.disconnect();\n        }}\n}});\n\n// Listen for the removal of the full notebook cells\nvar notebookContainer = gd.closest('#notebook-container');\nif (notebookContainer) {{\n    x.observe(notebookContainer, {childList: true});\n}}\n\n// Listen for the clearing of the current output cell\nvar outputEl = gd.closest('.output');\nif (outputEl) {{\n    x.observe(outputEl, {childList: true});\n}}\n\n                        })                };                });            </script>        </div>"},"metadata":{}}]}]}